{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bde7a-51c6-4078-a6f8-81262093074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231bb656-f894-44fe-874d-e0613fbb848d",
   "metadata": {},
   "source": [
    "# Part (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbf0b6-ec89-43fc-948f-977dfce2b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import over-35 dataset\n",
    "df = pd.read_csv('london_data_35+.csv')\n",
    "y = pd.CategoricalIndex(df.travel_mode).codes\n",
    "X = df.loc[:, df.columns != 'travel_mode'].to_numpy()\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Build train and validation dataloaders\n",
    "batch_size = 128\n",
    "X_train, y_train = X[:40000], y[:40000]\n",
    "X_val, y_val = X[40000:], y[40000:]\n",
    "train_dataset = TensorDataset(Tensor(X_train.copy()), Tensor(y_train.copy()))\n",
    "val_dataset = TensorDataset(Tensor(X_val.copy()), Tensor(y_val.copy()))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6eb842-dd65-4865-a6f8-cbf9c9b630cb",
   "metadata": {},
   "source": [
    "## Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ea1fd-384b-4df8-b4b2-33d39bc9b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(22, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d717c4-8f73-4a23-a6cd-a9d6e471f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork()\n",
    "optimizer = torch.optim.Adam(NN.parameters(), lr=1e-4)\n",
    "CrossEntropy = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90597d28-e7fd-463a-8fc7-d12c315c2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "for epoch in range(150):\n",
    "\n",
    "    # Training loop\n",
    "    train_acc = 0.0\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        pred = NN(X) # predict logits\n",
    "        loss = CrossEntropy(pred, y.type(torch.LongTensor)) # compute Cross Entropy loss\n",
    "        loss.backward() # backward pass\n",
    "        optimizer.step() # update step\n",
    "        optimizer.zero_grad()\n",
    "        train_acc += (pred.softmax(dim=1).argmax(dim=1) == y).type(torch.float).sum() / len(train_dataset)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # Validation loop\n",
    "    val_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(val_loader):\n",
    "            pred = NN(X)\n",
    "            loss = CrossEntropy(pred, y.type(torch.LongTensor))\n",
    "            val_acc += (pred.softmax(dim=1).argmax(dim=1) == y).type(torch.float).sum() / len(val_dataset)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1} train accuracy:, {round(float(train_acc), 4)}, validation accuracy:, {round(float(val_acc), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c5a0d-c66e-426d-80d5-e182f02a6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(train_acc_history, label='train')\n",
    "plt.plot(val_acc_history, label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abea264-5b01-4200-b4e6-20ec683ec895",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9296e-4e66-4d5b-b440-5e4c6a508bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training multi-class logistic regression model\n",
    "logistic = LogisticRegression(max_iter=5000, penalty=None).fit(X_train, y_train)\n",
    "print('train accuracy:', round(logistic.score(X_train, y_train), 3))\n",
    "print('validation accuracy:', round(logistic.score(X_val, y_val), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df596948-e089-4f3f-aa53-fa02ac53a673",
   "metadata": {},
   "source": [
    "# Part (ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf865d1e-3bdb-40d6-bdc3-cdb762e7b370",
   "metadata": {},
   "source": [
    "## Compare out-of-distribution accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d5df9-8f21-40e3-a00a-cc27dde8ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import under-35 dataset\n",
    "df = pd.read_csv('london_data_35-.csv')\n",
    "y = pd.CategoricalIndex(df.travel_mode).codes\n",
    "X = df.loc[:, df.columns != 'travel_mode'].to_numpy()\n",
    "X = scaler.transform(X)\n",
    "\n",
    "pred = NN(Tensor(X.copy()))\n",
    "acc = (pred.softmax(dim=1).argmax(dim=1) == Tensor(y.copy())).type(torch.float).sum() / X.shape[0]\n",
    "print('NN accuracy:', round(float(acc), 3))\n",
    "print('logistic accuracy:', round(logistic.score(X, y), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8a9b2-0f8b-4be8-b892-b5255be217bb",
   "metadata": {},
   "source": [
    "# Part (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eed83c-172d-40fd-a125-d3f0a81dc82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv('london_data_35-.csv'), pd.read_csv('london_data_35-.csv')])\n",
    "y = pd.CategoricalIndex(df.travel_mode).codes\n",
    "X = df.loc[:, df.columns != 'travel_mode'].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "train_dataset = TensorDataset(Tensor(X_train), Tensor(y_train))\n",
    "val_dataset = TensorDataset(Tensor(X_val), Tensor(y_val))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd442d-fbd6-4069-8145-f9d062affcf4",
   "metadata": {},
   "source": [
    "## Tune network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575c279-8236-4111-aec4-0d1f4227efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the following neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # ADD LAYERS\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b9f95-bbea-439b-a64b-f46f33380d52",
   "metadata": {},
   "source": [
    "## Tune learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57691661-368e-4de9-93e1-3c1e1c319c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = # SET LEARNING RATE\n",
    "epochs = # SET NUMBER OF EPOCHS\n",
    "\n",
    "NN = NeuralNetwork()\n",
    "optimizer = torch.optim.Adam(NN.parameters(), lr=lr)\n",
    "CrossEntropy = nn.CrossEntropyLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbdef5-77ff-4801-8bb4-c0ee8f835fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "for epoch in range(150):\n",
    "\n",
    "    # Training loop\n",
    "    train_acc = 0.0\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        pred = NN(X) # predict logits\n",
    "        loss = CrossEntropy(pred, y.type(torch.LongTensor)) # compute Cross Entropy loss\n",
    "        loss.backward() # backward pass\n",
    "        optimizer.step() # update step\n",
    "        optimizer.zero_grad()\n",
    "        train_acc += (pred.softmax(dim=1).argmax(dim=1) == y).type(torch.float).sum() / len(train_dataset)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # Validation loop\n",
    "    val_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(val_loader):\n",
    "            pred = NN(X)\n",
    "            loss = CrossEntropy(pred, y.type(torch.LongTensor))\n",
    "            val_acc += (pred.softmax(dim=1).argmax(dim=1) == y).type(torch.float).sum() / len(val_dataset)\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1} train accuracy:, {round(float(train_acc), 4)}, validation accuracy:, {round(float(val_acc), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b2b41-4023-4cba-8cf5-ee24a27a3867",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(train_acc_history, label='train')\n",
    "plt.plot(val_acc_history, label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f786c-d53b-47fc-8c76-296500b9cdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
