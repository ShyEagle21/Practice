{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a21e062",
   "metadata": {},
   "source": [
    "TO DO\n",
    "\n",
    "***Verify processes will only occur during specified times with specified labor\n",
    "    -Breaks\n",
    "\n",
    "***Fix National Carrier Processes\n",
    "    -Labor split and breaks for pallets\n",
    "    -Labor split and breaks for fluid\n",
    "\n",
    "Determine the process tracking mechanism for a wholistic process\n",
    "\n",
    "***Ensure appropriate completion times documented for all processes/partitions/carriers etc.\n",
    "\n",
    "Determine if there is value in adding downtime for handoffs.\n",
    "    -Specifically how to change between batch handoff process and dedicated handoff process.\n",
    "    -Generally how should I consider handoffs and their impact in overall labor hour times\n",
    "\n",
    "Consider building pallets or carts in a different way\n",
    "\n",
    "***Evaluate the variance of processes based on historic rates and known numbers of team members\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***Need to build and train the model which will predict the number of packages per truck and the time of arrival for the trucks\n",
    "\n",
    "***Need to investigate if the distribution of packages follows any sort of trend, specifically partition 1, 2, 3, each of the national carriers\n",
    "    -Would it be accurate to assume a random distribution of the packages based on a random splitting of the packages?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "System process flow would occur as follows:\n",
    "    1. Prediction model takes input of yesterday's or 2 day's prior volume, CART prediction, etc and generates a total expected volume\n",
    "    2. The prediction model then predicts when the trucks will arrive based on their routebooks and historic arrivals\n",
    "    3. Packages will be assigned a partition, or a national carrier based on the historical overall distribution of package compostion\n",
    "    4. Packages will be assigned to trucks/pallets randomly or based on historical trends as far as truck fill rates.\n",
    "    5. CSV file will be generated and fed to the simulation model (interim solution, full solution will just feed the df into the simulation)\n",
    "    6. Simulation is run X times (say 1000) and the completion probability/carryover probability is calculated.\n",
    "    7. Average of all the completion times is calculated and used to generate a progress tracker for each of the shifts \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269a4fe",
   "metadata": {},
   "source": [
    "# Define Classes, Libraries, and Global Variables that will be used across all simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9744282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import numpy as np\n",
    "import sim_generator as sg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import simpy\n",
    "\n",
    "class G:\n",
    "    # Constants (adjust as needed)\n",
    "    Process_Variance = 0.1\n",
    "    UNLOADING_RATE = 60/15  # minutes per pallet\n",
    "    UNLOADING_VARIANCE = Process_Variance  # 10% variance\n",
    "    INDUCT_STAGE_RATE = 60/22  # minutes per pallet\n",
    "    INDUCT_STAGE_VARIANCE = Process_Variance  # 10% variance\n",
    "    INDUCTION_RATE = 60/800  # minutes per package\n",
    "    INDUCTION_VARIANCE = Process_Variance  # 10% variance\n",
    "    SPLITTER_RATE = 1/60  # minutes per package\n",
    "    SPLITTER_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_BUFFER_SORT_RATE = 60/148  # minutes per package\n",
    "    TLMD_BUFFER_SORT_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_PARTITION_STAGE_RATE = 1  # minutes per pallet\n",
    "    TLMD_PARTITION_STAGE_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_INDUCT_STAGE_RATE = 60/15  # minutes per pallet\n",
    "    TLMD_INDUCT_STAGE_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_INDUCTION_RATE = 60/300  # minutes per package\n",
    "    TLMD_INDUCTION_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_FINAL_SORT_RATE = 60/84  # minutes per package\n",
    "    TLMD_FINAL_SORT_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_CART_STAGE_RATE = 60/84  # minutes per cart\n",
    "    TLMD_CART_STAGE_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_CART_HANDOFF_RATE = 60/22  # minutes per pallet\n",
    "    TLMD_CART_HANDOFF_VARIANCE = Process_Variance  # 10% variance\n",
    "    CART_STAGE_RATE = 2  # minutes per cart\n",
    "    CART_STAGE_VARIANCE = Process_Variance  # 10% variance\n",
    "    TLMD_CART_HANDOFF_RATE = 2  # minutes per cart\n",
    "    TLMD_CART_HANDOFF_VARIANCE = Process_Variance  # 10% variance\n",
    "    NATIONAL_CARRIER_SORT_RATE = 60/148  # minutes per package\n",
    "    NATIONAL_CARRIER_SORT_VARIANCE = Process_Variance  # 10% variance\n",
    "    NC_PALLET_STAGING_RATE = 60/120  # minutes per pallet\n",
    "    NC_PALLET_STAGING_VARIANCE = Process_Variance  # 10% variance\n",
    "    NATIONAL_CARRIER_FLUID_PICK_RATE = 1/60  # minutes per package\n",
    "    NATIONAL_CARRIER_FLUID_PICK_VARIANCE = Process_Variance  # 10% variance\n",
    "    NATIONAL_CARRIER_FLUID_LOAD_RATE = 60/120  # minutes per package\n",
    "    NATIONAL_CARRIER_FLUID_LOAD_VARIANCE = Process_Variance  # 10% variance\n",
    "    \n",
    "\n",
    "\n",
    "    OUTBOUND_NC_PALLET_MAX_PACKAGES = 50  # Max packages per pallet\n",
    "    PARTITION_PALLET_MAX_PACKAGES = 50  # Max packages per pallet\n",
    "    TLMD_PARTITION_PALLET_MAX_PACKAGES = 50  # Max packages per pallet\n",
    "    NC_PALLET_MAX_PACKAGES = 50  # Max packages per pallet\n",
    "    TLMD_CART_MAX_PACKAGES = 20  # Max packages per cart\n",
    "    TOTAL_PACKAGES = None  # Total packages to be processed\n",
    "    TOTAL_PACKAGES_TLMD = None  # Total TLMD packages to be processed\n",
    "    TOTAL_PACKAGES_NC = None  # Total National Carrier packages to be processed\n",
    "    TLMD_AB_INDUCT_TIME = None\n",
    "    TLMD_C_INDUCT_TIME = None\n",
    "    TLMD_STAGED_PACKAGES = None\n",
    "    TLMD_PARTITION_1_PACKAGES = None\n",
    "    TLMD_PARTITION_2_PACKAGES = None\n",
    "    TLMD_PARTITION_3_PACKAGES = None\n",
    "    TOTAL_PALLETS_TLMD = None\n",
    "    TLMD_PARTITION_1_SORT_TIME = None\n",
    "    TLMD_PARTITION_2_SORT_TIME = None \n",
    "    TLMD_PARTITION_3_SORT_TIME = None\n",
    "    TLMD_SORTED_PACKAGES = None\n",
    "    TLMD_PARTITION_1_CART_STAGE_TIME = None\n",
    "    TLMD_PARTITION_2_CART_STAGE_TIME = None \n",
    "    TLMD_PARTITION_3_CART_STAGE_TIME = None\n",
    "    TLMD_OUTBOUND_PACKAGES = None\n",
    "    I=1\n",
    "    J=1\n",
    "    K=1\n",
    "    PASSED_OVER_PALLETS_1 = None\n",
    "    PASSED_OVER_PALLETS_2 = None\n",
    "    PASSED_OVER_PALLETS_3 = None\n",
    "\n",
    "    TOTAL_LINEHAUL_A_PACKAGES = None\n",
    "    TOTAL_LINEHAUL_B_PACKAGES = None\n",
    "    TOTAL_LINEHAUL_C_PACKAGES = None\n",
    "\n",
    "    USPS_LINEHAUL_A_PACKAGES = None\n",
    "    USPS_LINEHAUL_B_PACKAGES = None\n",
    "    USPS_LINEHAUL_C_PACKAGES = None\n",
    "\n",
    "    UPSN_LINEHAUL_A_PACKAGES = None\n",
    "    UPSN_LINEHAUL_B_PACKAGES = None\n",
    "    UPSN_LINEHAUL_C_PACKAGES = None\n",
    "\n",
    "    FDEG_LINEHAUL_A_PACKAGES = None\n",
    "    FDEG_LINEHAUL_B_PACKAGES = None\n",
    "    FDEG_LINEHAUL_C_PACKAGES = None\n",
    "\n",
    "    FDE_LINEHAUL_A_PACKAGES = None\n",
    "    FDE_LINEHAUL_B_PACKAGES = None\n",
    "    FDE_LINEHAUL_C_PACKAGES = None\n",
    "\n",
    "    TLMD_LINEHAUL_A_PACKAGES = None\n",
    "    TLMD_LINEHAUL_B_PACKAGES = None\n",
    "    TLMD_LINEHAUL_C_PACKAGES = None\n",
    "\n",
    "    TLMD_LINEHAUL_TFC_PACKAGES=None\n",
    "\n",
    "    LINEHAUL_C_TIME = None\n",
    "    LINEHAUL_TFC_TIME = None\n",
    "\n",
    "    TOTAL_PACKAGES_UPSN = None\n",
    "    TOTAL_PACKAGES_USPS = None\n",
    "    TOTAL_PACKAGES_FDEG = None\n",
    "    TOTAL_PACKAGES_FDE = None\n",
    "    UPSN_PALLETS = None\n",
    "    USPS_PALLETS = None\n",
    "    FDEG_PALLETS = None\n",
    "    FDE_PALLETS = None\n",
    "    UPSN_SORT_TIME = None\n",
    "    USPS_SORT_TIME = None\n",
    "    FDEG_SORT_TIME = None\n",
    "    FDE_SORT_TIME = None\n",
    "\n",
    "    TOTAL_CARTS_TLMD = None\n",
    "\n",
    "    PARTITION_1_RATIO = 0.50  # Ratio of packages to go to partition 1\n",
    "    PARTITION_2_RATIO = 0.35  # Ratio of packages to go to partition 2\n",
    "    PARTITION_3_RATIO = 0.15  # Ratio of packages to go to partition 3\n",
    "\n",
    "    USPS_DEPARTURE_TIME = [780]  # minutes\n",
    "    UPSN_DEPARTURE_TIME = [1440]  # minutes\n",
    "    FDEG_DEPARTURE_TIME = [180, 390]  # minutes\n",
    "    FDE_DEPARTURE_TIME = [330]  # minutes\n",
    "\n",
    "class Package:\n",
    "    def __init__(self, tracking_number, pallet_id, scac):\n",
    "        self.tracking_number = tracking_number\n",
    "        self.pallet_id = pallet_id\n",
    "        self.scac = scac\n",
    "        self.current_queue = None\n",
    "\n",
    "class Pallet:\n",
    "    def __init__(self, env, pallet_id, packages, pkg_received_utc_ts):\n",
    "        self.env = env\n",
    "        self.pkg_received_utc_ts = pkg_received_utc_ts\n",
    "        self.pallet_id = pallet_id\n",
    "        self.packages = [Package(pkg[0], pallet_id, pkg[1]) for pkg in packages]\n",
    "        self.current_queue = None\n",
    "        self.remaining_packages = len(packages)  # Track remaining packages\n",
    "\n",
    "class TLMD_Pallet:\n",
    "    def __init__(self, env, pallet_id, packages, built_time):\n",
    "        self.env = env\n",
    "        self.built_time = built_time\n",
    "        self.pallet_id = pallet_id\n",
    "        self.packages = packages\n",
    "        self.current_packages = len(packages)  # Track remaining packages\n",
    "\n",
    "    def add_package(self, package):\n",
    "        self.packages.append(package)\n",
    "        self.current_packages = len(self.packages)  # Update the count\n",
    "        print(f'Package {package.tracking_number} added to pallet {self.pallet_id} at {self.env.now}')\n",
    "        print(f'Pallet currently contains {self.current_packages} packages')\n",
    "\n",
    "class TLMD_Cart:\n",
    "    def __init__(self, env, cart_id, packages, built_time):\n",
    "        self.env = env\n",
    "        self.built_time = built_time\n",
    "        self.cart_id = cart_id\n",
    "        self.packages = packages\n",
    "        self.current_packages = len(packages)  # Tracks packages\n",
    "    \n",
    "    def add_package(self, package):\n",
    "        self.packages.append(package)\n",
    "        self.current_packages = len(self.packages)  # Update the count\n",
    "        print(f\"Package {package.tracking_number} added to cart {self.cart_id} at {self.env.now}\")\n",
    "        #print(f'Cart currently contains {self.current_packages} packages')\n",
    "\n",
    "class National_Carrier_Pallet:\n",
    "    def __init__(self, env, pallet_id, packages, scac, built_time):\n",
    "        self.env = env\n",
    "        self.built_time = built_time\n",
    "        self.pallet_id = pallet_id\n",
    "        self.packages = packages\n",
    "        self.scac = scac\n",
    "        self.current_packages = len(packages)  # Track remaining packages\n",
    "\n",
    "    def add_package(self, package):\n",
    "        self.packages.append(package)\n",
    "        self.current_packages = len(self.packages)  # Update the count\n",
    "        print(f\"Package {package.tracking_number} added to pallet {self.pallet_id} at {self.env.now}\")\n",
    "        #print(f'Pallet currently contains {self.current_packages} packages')\n",
    "\n",
    "def manage_resources(env, sortation_center, current_resource, \n",
    "                     night_tm_pit_unload, \n",
    "                        night_tm_pit_induct, \n",
    "                        night_tm_nonpit_split, \n",
    "                        night_tm_nonpit_NC, \n",
    "                        night_tm_nonpit_buffer,\n",
    "                        night_tm_TLMD_induct,\n",
    "                        night_tm_TLMD_picker,\n",
    "                        night_tm_TLMD_sort,\n",
    "                        night_tm_TLMD_stage,\n",
    "                        day_tm_pit_unload,\n",
    "                        day_tm_pit_induct,\n",
    "                        day_tm_nonpit_split,\n",
    "                        day_tm_nonpit_NC,\n",
    "                        day_tm_nonpit_buffer,\n",
    "                        day_tm_TLMD_induct,\n",
    "                        day_tm_TLMD_picker,\n",
    "                        day_tm_TLMD_sort,\n",
    "                        day_tm_TLMD_stage):\n",
    "    \n",
    "        yield env.timeout(30)\n",
    "        # Start with 1 resource for the first 10 minutes\n",
    "        sortation_center.current_resource['tm_pit_unload'] = simpy.Resource(env, capacity=night_tm_pit_unload)\n",
    "        sortation_center.current_resource['tm_pit_induct'] = simpy.PriorityResource(env, capacity=night_tm_pit_induct)\n",
    "        sortation_center.current_resource['tm_nonpit_split'] = simpy.Resource(env, capacity=night_tm_nonpit_split)\n",
    "        sortation_center.current_resource['tm_nonpit_NC'] = simpy.PriorityResource(env, capacity=night_tm_nonpit_NC)\n",
    "        sortation_center.current_resource['tm_nonpit_buffer'] = simpy.PriorityResource(env, capacity=night_tm_nonpit_buffer)\n",
    "        sortation_center.current_resource['tm_TLMD_induct'] = simpy.PriorityResource(env, capacity=night_tm_TLMD_induct)\n",
    "        sortation_center.current_resource['tm_TLMD_picker'] = simpy.Resource(env, capacity=night_tm_TLMD_picker)\n",
    "        sortation_center.current_resource['tm_TLMD_sort'] = simpy.Resource(env, capacity=night_tm_TLMD_sort)\n",
    "        sortation_center.current_resource['tm_TLMD_stage'] = simpy.Resource(env, capacity=night_tm_TLMD_stage)\n",
    "\n",
    "        print(f\"Using nightshift resources at time {env.now}\")\n",
    "        yield env.timeout(600)\n",
    "        print(f'Between Shift Break')\n",
    "        yield env.timeout(30)\n",
    "        print(f'Using dayshift resources at time {env.now}')\n",
    "\n",
    "        # Switch to 5 resources for the next 30 minutes\n",
    "        sortation_center.current_resource['tm_pit_unload'] = simpy.Resource(env, capacity=day_tm_pit_unload)\n",
    "        sortation_center.current_resource['tm_pit_induct'] = simpy.PriorityResource(env, capacity=day_tm_pit_induct)\n",
    "        sortation_center.current_resource['tm_nonpit_split'] = simpy.Resource(env, capacity=day_tm_nonpit_split)\n",
    "        sortation_center.current_resource['tm_nonpit_NC'] = simpy.PriorityResource(env, capacity=day_tm_nonpit_NC)\n",
    "        sortation_center.current_resource['tm_nonpit_buffer'] = simpy.PriorityResource(env, capacity=day_tm_nonpit_buffer)\n",
    "        sortation_center.current_resource['tm_TLMD_induct'] = simpy.PriorityResource(env, capacity=day_tm_TLMD_induct)\n",
    "        sortation_center.current_resource['tm_TLMD_picker'] = simpy.Resource(env, capacity=day_tm_TLMD_picker)\n",
    "        sortation_center.current_resource['tm_TLMD_sort'] = simpy.Resource(env, capacity=day_tm_TLMD_sort)\n",
    "        sortation_center.current_resource['tm_TLMD_stage'] = simpy.Resource(env, capacity=day_tm_TLMD_stage)\n",
    "        yield env.timeout(600)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linehaul_C_arrival(env, sortation_center):\n",
    "    yield env.timeout(G.LINEHAUL_C_TIME)\n",
    "    print(f'Linehaul C arrival at {env.now}')\n",
    "    sortation_center.LHC_flag = True\n",
    "    \n",
    "\n",
    "def plot_metrics(metrics):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(metrics['resource_utilization'])\n",
    "    plt.title('util')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('util')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    for queue, lengths in metrics['queue_lengths'].items():\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.plot(lengths, label=queue)\n",
    "        plt.title('Queue Length')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Queue Length')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f7846c",
   "metadata": {},
   "source": [
    "# 24 Hour Soration Center Process Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d82709d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sortation_Center:\n",
    "    def __init__(self, \n",
    "                env, \n",
    "                pallets_df, \n",
    "                night_tm_pit_unload, \n",
    "                night_tm_pit_induct, \n",
    "                night_tm_nonpit_split, \n",
    "                night_tm_nonpit_NC, \n",
    "                night_tm_nonpit_buffer,\n",
    "                night_tm_TLMD_induct,\n",
    "                night_tm_TLMD_picker,\n",
    "                night_tm_TLMD_sort,\n",
    "                night_tm_TLMD_stage,\n",
    "                day_tm_pit_unload,\n",
    "                day_tm_pit_induct,\n",
    "                day_tm_nonpit_split,\n",
    "                day_tm_nonpit_NC,\n",
    "                day_tm_nonpit_buffer,\n",
    "                day_tm_TLMD_induct,\n",
    "                day_tm_TLMD_picker,\n",
    "                day_tm_TLMD_sort,\n",
    "                day_tm_TLMD_stage,\n",
    "                USPS_Fluid_Status,\n",
    "                UPSN_Fluid_Status,\n",
    "                FDEG_Fluid_Status,\n",
    "                FDE_Fluid_Status,\n",
    "                current_resources\n",
    "                ):\n",
    "        \n",
    "        self.env = env\n",
    "        self.pallets_df = pallets_df\n",
    "\n",
    "        self.current_resource = current_resources\n",
    "\n",
    "        #Determine whether National Carrier is performed as Fluid or Pallet\n",
    "        self.USPS_Fluid_Status = USPS_Fluid_Status\n",
    "        self.UPSN_Fluid_Status = UPSN_Fluid_Status\n",
    "        self.FDEG_Fluid_Status = FDEG_Fluid_Status\n",
    "        self.FDE_Fluid_Status = FDE_Fluid_Status\n",
    "\n",
    "        #Used for consideration of breaks\n",
    "        self.resources_available = True\n",
    "\n",
    "        #flags used to control whether day shift resources or night shift resources are used.\n",
    "        self.night_shift = False\n",
    "        self.day_shift = False\n",
    "\n",
    "        #flags to control the resources dedicated to processes\n",
    "        self.inbound_flag = False\n",
    "        self.TLMD_flag = False\n",
    "        self.TLMD_sort = False\n",
    "        self.TLMD_stage = False\n",
    "        self.LHC_flag = False\n",
    "\n",
    "        #flags for national carrier progress\n",
    "        self.USPS_AB_flag = False\n",
    "        self.UPSN_AB_flag = False\n",
    "        self.FDEG_AB_flag = False\n",
    "        self.FDE_ABflag = False\n",
    "        self.TLMD_AB_flag = False\n",
    "        self.inbound_C_flag = False\n",
    "\n",
    "        self.partition_1_flag = False\n",
    "        self.partition_2_flag = False\n",
    "        self.partition_3_flag = False\n",
    "\n",
    "        self.queues = {\n",
    "            'queue_inbound_truck': simpy.Store(self.env),\n",
    "            'queue_inbound_staging': simpy.Store(self.env, capacity=200),\n",
    "            'queue_induct_staging_pallets': simpy.Store(self.env),\n",
    "            'queue_induct_staging_packages': simpy.Store(self.env),\n",
    "            'queue_splitter': simpy.Store(self.env, capacity=1),\n",
    "            'queue_tlmd_buffer_sort': simpy.Store(self.env, capacity=100000),\n",
    "            'queue_national_carrier_sort': simpy.Store(self.env, capacity=100000),\n",
    "            'queue_tlmd_pallet': simpy.Store(self.env, capacity=100000),  \n",
    "            \"queue_FDEG_pallet\": simpy.Store(self.env),\n",
    "            \"queue_FDE_pallet\": simpy.Store(self.env),\n",
    "            \"queue_USPS_pallet\": simpy.Store(self.env),\n",
    "            \"queue_UPSN_pallet\": simpy.Store(self.env), \n",
    "            'queue_FDEG_staged_pallet': simpy.Store(self.env),\n",
    "            'queue_FDE_staged_pallet': simpy.Store(self.env),\n",
    "            'queue_USPS_staged_pallet': simpy.Store(self.env),\n",
    "            'queue_UPSN_staged_pallet': simpy.Store(self.env),\n",
    "            \"queue_FDEG_fluid\": simpy.Store(self.env, capacity=10),\n",
    "            \"queue_FDE_fluid\": simpy.Store(self.env, capacity=10),\n",
    "            \"queue_USPS_fluid\": simpy.Store(self.env, capacity=10),\n",
    "            \"queue_UPSN_fluid\": simpy.Store(self.env, capacity=10),\n",
    "            'queue_FDEG_outbound_packages': simpy.Store(self.env),\n",
    "            'queue_FDE_outbound_packages': simpy.Store(self.env),\n",
    "            'queue_USPS_outbound_packages': simpy.Store(self.env),\n",
    "            'queue_UPSN_outbound_packages': simpy.Store(self.env),\n",
    "            'queue_tlmd_1_staged_pallet': simpy.Store(env),\n",
    "            'queue_tlmd_2_staged_pallet': simpy.Store(env),\n",
    "            'queue_tlmd_3_staged_pallet': simpy.Store(env),\n",
    "            'queue_tlmd_induct_staging_pallets' : simpy.Store(env, capacity=6),\n",
    "            'queue_tlmd_induct_staging_packages' : simpy.Store(env),\n",
    "            'queue_tlmd_splitter' : simpy.Store(env, capacity = 1),\n",
    "            'queue_tlmd_final_sort' : simpy.Store(env),\n",
    "            'queue_tlmd_cart' : simpy.Store(env),  \n",
    "            'queue_tlmd_1_cart' : simpy.Store(env),\n",
    "            'queue_tlmd_2_cart' : simpy.Store(env),\n",
    "            'queue_tlmd_3_cart' : simpy.Store(env),  \n",
    "            'queue_tlmd_cart_1_staging' : simpy.Store(env),\n",
    "            'queue_tlmd_cart_2_staging' : simpy.Store(env),\n",
    "            'queue_tlmd_cart_3_staging' : simpy.Store(env),\n",
    "            'queue_tlmd_cart_handoff' : simpy.Store(env),\n",
    "        }\n",
    "\n",
    "        self.metrics = {\n",
    "            'processing_times': [],\n",
    "            'queue_lengths': {key: [] for key in self.queues.keys()},\n",
    "            'resource_utilization': [],\n",
    "        }\n",
    "\n",
    "        self.all_packages_staged_time = None\n",
    "\n",
    "    def track_metrics(self):\n",
    "        while True:\n",
    "            for key, queue in self.queues.items():\n",
    "                self.metrics['queue_lengths'][key].append(len(queue.items))\n",
    "            #self.metrics['resource_utilization'].append(len(self.night_tm_pit_unload.queue))\n",
    "            yield self.env.timeout(1)\n",
    "\n",
    "    \n",
    "\n",
    "    def schedule_arrivals(self):\n",
    "        for i, row in self.pallets_df.iterrows():\n",
    "            pallet = Pallet(\n",
    "                self.env,\n",
    "                row['Pallet'],\n",
    "                row['packages'],\n",
    "                row['earliest_arrival']\n",
    "            )\n",
    "            self.env.process(self.truck_arrival(pallet))\n",
    "\n",
    "    def truck_arrival(self, pallet):\n",
    "        yield self.env.timeout(pallet.pkg_received_utc_ts) \n",
    "        pallet.current_queue = 'queue_inbound_truck'\n",
    "        print(f'Pallet {pallet.pallet_id} arrived at {self.env.now}')\n",
    "        yield self.queues['queue_inbound_truck'].put(pallet)\n",
    "        self.env.process(self.unload_truck(pallet))\n",
    "\n",
    "####################################\n",
    "####inbound induct proces start#####\n",
    "####################################\n",
    "\n",
    "    def unload_truck(self, pallet):\n",
    "\n",
    "        with self.current_resource['tm_pit_unload'].request() as req:\n",
    "            yield req\n",
    "            yield self.queues['queue_inbound_truck'].get()\n",
    "            yield self.env.timeout(G.UNLOADING_RATE)  # Unloading time\n",
    "            pallet.current_queue = 'queue_inbound_staging'\n",
    "            print(f'Pallet {pallet.pallet_id} unloaded at {self.env.now}')\n",
    "            yield self.queues['queue_inbound_staging'].put(pallet)\n",
    "            self.env.process(self.move_to_induct_staging(pallet))\n",
    "\n",
    "    def move_to_induct_staging(self, pallet):\n",
    "\n",
    "        \n",
    "        #while self.day_shift and not self.partition_2_flag:\n",
    "            #yield self.env.timeout(1)\n",
    "\n",
    "        with self.current_resource['tm_pit_induct'].request(priority=1) as req: \n",
    "            yield req\n",
    "            yield self.queues['queue_inbound_staging'].get()\n",
    "            yield self.env.timeout(G.INDUCT_STAGE_RATE)  # Unloading time\n",
    "            pallet.current_queue = 'queue_induct_staging_pallets'\n",
    "            yield self.queues['queue_induct_staging_pallets'].put(pallet)\n",
    "            print(f'Pallet {pallet.pallet_id} staged for induction at {self.env.now}')\n",
    "            for package in pallet.packages:\n",
    "                package.current_queue = 'queue_induct_staging_packages'\n",
    "                yield self.queues['queue_induct_staging_packages'].put(package)\n",
    "                self.env.process(self.induct_package(package, pallet))\n",
    "\n",
    "    def induct_package(self, package, pallet):\n",
    "\n",
    "\n",
    "        with self.current_resource['tm_pit_induct'].request(priority=0) as req:  \n",
    "            yield req\n",
    "            yield self.queues['queue_induct_staging_packages'].get()\n",
    "            yield self.env.timeout(G.INDUCTION_RATE)\n",
    "            package.current_queue = 'queue_splitter'\n",
    "            print(f'Package {package.tracking_number}, {package.scac} inducted at {self.env.now}')\n",
    "            yield self.queues['queue_splitter'].put(package)\n",
    "            pallet.remaining_packages -= 1  # Decrement the counter\n",
    "            if pallet.remaining_packages == 0:\n",
    "                # Remove the pallet from queue_induct_staging_pallets\n",
    "                self.remove_pallet_from_queue(pallet)\n",
    "            self.env.process(self.split_package(package))\n",
    "        \n",
    "        \n",
    "    def remove_pallet_from_queue(self, pallet):\n",
    "        # Manually search for and remove the pallet from the queue\n",
    "        for i, p in enumerate(self.queues['queue_induct_staging_pallets'].items):\n",
    "            if p.pallet_id == pallet.pallet_id:\n",
    "                del self.queues['queue_induct_staging_pallets'].items[i]\n",
    "                print(f'Pallet {pallet.pallet_id} removed from queue_induct_staging_pallets at {self.env.now}')\n",
    "                break\n",
    "\n",
    "    def split_package(self, package):\n",
    "\n",
    "        with self.current_resource['tm_nonpit_split'].request() as req:\n",
    "            yield req\n",
    "            yield self.queues['queue_splitter'].get()\n",
    "            if package.scac in ['UPSN', 'USPS', 'FDEG', 'FDE']:\n",
    "                package.current_queue = 'queue_national_carrier_sort'\n",
    "                print(f'Package {package.tracking_number} split to National Sort at {self.env.now}')\n",
    "                yield self.queues['queue_national_carrier_sort'].put(package)\n",
    "                self.env.process(self.national_carrier_sort(package))\n",
    "            else:\n",
    "                package.current_queue = 'queue_tlmd_buffer_sort'\n",
    "                print(f'Package {package.tracking_number} split to TLMD Buffer at {self.env.now}')\n",
    "                yield self.queues['queue_tlmd_buffer_sort'].put(package)\n",
    "                self.env.process(self.tlmd_buffer_sort(package))\n",
    "\n",
    "    def national_carrier_sort(self, package):\n",
    "\n",
    "        with self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_national_carrier_sort\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_SORT_RATE)\n",
    "            if package.scac in ['UPSN']:\n",
    "                if not self.UPSN_Fluid_Status:\n",
    "                    yield self.queues[\"queue_UPSN_pallet\"].put(package)\n",
    "                    self.env.process(self.check_all_UPSN_sorted())\n",
    "                else:\n",
    "                    yield self.queues[\"queue_UPSN_fluid\"].put(package)\n",
    "                    self.env.process(self.national_carrier_fluid_split_UPSN(package))\n",
    "            elif package.scac in ['USPS']:\n",
    "                if not self.USPS_Fluid_Status:\n",
    "                    yield self.queues[\"queue_USPS_pallet\"].put(package)\n",
    "                    self.env.process(self.check_all_USPS_sorted())\n",
    "                else:\n",
    "                    yield self.queues[\"queue_USPS_fluid\"].put(package)\n",
    "                    self.env.process(self.national_carrier_fluid_split_USPS(package))\n",
    "            elif package.scac in ['FDEG']:\n",
    "                if not self.FDEG_Fluid_Status:\n",
    "                    yield self.queues[\"queue_FDEG_pallet\"].put(package)\n",
    "                    self.env.process(self.check_all_FDEG_sorted())\n",
    "                else:\n",
    "                    yield self.queues[\"queue_FDEG_fluid\"].put(package)\n",
    "                    self.env.process(self.national_carrier_fluid_split_FDEG(package))\n",
    "            elif package.scac in ['FDE']:\n",
    "                if not self.FDE_Fluid_Status:\n",
    "                    yield self.queues[\"queue_FDE_pallet\"].put(package)\n",
    "                    self.env.process(self.check_all_FDE_sorted())\n",
    "                else:\n",
    "                    yield self.queues[\"queue_FDE_fluid\"].put(package)\n",
    "                    self.env.process(self.national_carrier_fluid_split_FDE(package))\n",
    "\n",
    "    \n",
    "        \n",
    "    def check_all_UPSN_sorted(self):\n",
    "        if len(self.queues['queue_UPSN_pallet'].items) == G.UPSN_LINEHAUL_A_PACKAGES + G.UPSN_LINEHAUL_B_PACKAGES:\n",
    "            print(f'All A&B UPSN packages sorted at {self.env.now}')\n",
    "            G.UPSN_SORT_TIME = self.env.now \n",
    "            self.UPSN_AB_flag = True\n",
    "            self.env.process(self.NC_UPSN_pallet_build())\n",
    "        elif self.UPSN_AB_flag and len(self.queues['queue_UPSN_fluid'].items) == G.UPSN_LINEHAUL_C_PACKAGES:\n",
    "            print(f'All C UPSN packages sorted at {self.env.now}')\n",
    "            self.env.process(self.NC_UPSN_pallet_build())\n",
    "        else:\n",
    "            yield self.env.timeout(1)\n",
    "            self.env.process(self.check_all_UPSN_sorted())\n",
    "\n",
    "    def check_all_USPS_sorted(self):\n",
    "        if len(self.queues['queue_USPS_pallet'].items) == G.USPS_LINEHAUL_A_PACKAGES + G.USPS_LINEHAUL_B_PACKAGES:\n",
    "            print(f'All A&B USPS packages sorted at {self.env.now}')\n",
    "            G.USPS_SORT_TIME = self.env.now\n",
    "            self.USPS_AB_flag = True\n",
    "            self.env.process(self.NC_USPS_pallet_build())\n",
    "        elif self.USPS_AB_flag and len(self.queues['queue_USPS_fluid'].items) == G.USPS_LINEHAUL_C_PACKAGES:\n",
    "            print(f'All C USPS packages sorted at {self.env.now}')\n",
    "            self.env.process(self.NC_USPS_pallet_build())\n",
    "        else:\n",
    "            yield self.env.timeout(1)\n",
    "            self.env.process(self.check_all_USPS_sorted())\n",
    "\n",
    "    def check_all_FDEG_sorted(self):\n",
    "        if  len(self.queues['queue_FDEG_pallet'].items) == G.FDEG_LINEHAUL_A_PACKAGES + G.FDEG_LINEHAUL_B_PACKAGES:\n",
    "            print(f'All A&B FDEG packages sorted at {self.env.now}')\n",
    "            G.FDEG_SORT_TIME = self.env.now\n",
    "            self.FDEG_AB_flag = True\n",
    "            self.env.process(self.NC_FDEG_pallet_build())\n",
    "        elif self.FDEG_AB_flag and len(self.queues['queue_FDEG_fluid'].items) == G.FDEG_LINEHAUL_C_PACKAGES:\n",
    "            print(f'All C FDEG packages sorted at {self.env.now}')\n",
    "            self.env.process(self.NC_FDEG_pallet_build())\n",
    "        else:\n",
    "            yield self.env.timeout(1)\n",
    "            self.env.process(self.check_all_FDEG_sorted())\n",
    "\n",
    "    def check_all_FDE_sorted(self):\n",
    "        if  len(self.queues['queue_FDE_pallet'].items) == G.FDE_LINEHAUL_A_PACKAGES + G.FDE_LINEHAUL_B_PACKAGES:\n",
    "            print(f'All A&B FDE packages sorted at {self.env.now}')\n",
    "            G.FDE_SORT_TIME = self.env.now\n",
    "            self.FDE__ABflag = True\n",
    "            self.env.process(self.NC_FDE_pallet_build())\n",
    "        elif self.FDE_ABflag and len(self.queues['queue_FDE_fluid'].items) == G.FDE_LINEHAUL_C_PACKAGES:\n",
    "            print(f'All C FDE packages sorted at {self.env.now}')\n",
    "            self.env.process(self.NC_FDE_pallet_build())\n",
    "        else:\n",
    "            yield self.env.timeout(1)\n",
    "            self.env.process(self.check_all_FDE_sorted())           \n",
    "\n",
    "    def NC_UPSN_pallet_build(self):\n",
    "        UPSN_pallets = math.ceil(G.TOTAL_PACKAGES_UPSN / G.NC_PALLET_MAX_PACKAGES)\n",
    "        print(f'UPSN: {UPSN_pallets} pallets')\n",
    "        G.UPSN_PALLETS = UPSN_pallets\n",
    "\n",
    "        def create_NC_pallets(NC_packages, NC_pallets, queue_name, staged_queue_name, scac):\n",
    "\n",
    "            with self.current_resource['tm_nonpit_NC'].request(priority=0) as req:\n",
    "                yield req\n",
    "                remaining_packages = NC_packages\n",
    "                for pallet_num in range(NC_pallets):\n",
    "                    pallet_packages = []\n",
    "                    packages_for_this_pallet = min(G.NC_PALLET_MAX_PACKAGES, remaining_packages)\n",
    "                    for _ in range(packages_for_this_pallet):\n",
    "                        pkg = yield self.queues[queue_name].get()\n",
    "                        pallet_packages.append(pkg)\n",
    "                        yield self.env.timeout(0)\n",
    "                    pallet = National_Carrier_Pallet(self.env, f'Pallet_{G.K}', pallet_packages, scac, self.env.now)\n",
    "                    G.K += 1\n",
    "                    print(f'NC_{scac}, {pallet.pallet_id} created with {len(pallet_packages)} packages at {self.env.now}')\n",
    "                    yield self.queues[staged_queue_name].put(pallet)\n",
    "                    yield self.env.timeout(G.NC_PALLET_STAGING_RATE)\n",
    "                    remaining_packages -= packages_for_this_pallet\n",
    "\n",
    "        yield self.env.process(create_NC_pallets(G.TOTAL_PACKAGES_UPSN, UPSN_pallets, 'queue_UPSN_pallet', 'queue_UPSN_staged_pallet','UPSN'))\n",
    "\n",
    "    def NC_USPS_pallet_build(self):\n",
    "        USPS_pallets = math.ceil(G.TOTAL_PACKAGES_USPS / G.NC_PALLET_MAX_PACKAGES)\n",
    "        print(f'USPS: {USPS_pallets} pallets')\n",
    "        G.USPS_PALLETS = USPS_pallets\n",
    "\n",
    "        def create_NC_pallets(NC_packages, NC_pallets, queue_name, staged_queue_name, scac):\n",
    "\n",
    "            with self.current_resource['tm_nonpit_NC'].request(priority=0) as req:\n",
    "                yield req\n",
    "                remaining_packages = NC_packages\n",
    "                for pallet_num in range(NC_pallets):\n",
    "                    pallet_packages = []\n",
    "                    packages_for_this_pallet = min(G.NC_PALLET_MAX_PACKAGES, remaining_packages)\n",
    "                    for _ in range(packages_for_this_pallet):\n",
    "                        pkg = yield self.queues[queue_name].get()\n",
    "                        pallet_packages.append(pkg)\n",
    "                        yield self.env.timeout(0)\n",
    "                    pallet = National_Carrier_Pallet(self.env, f'Pallet_{G.K}', pallet_packages, scac, self.env.now)\n",
    "                    G.K += 1\n",
    "                    print(f'NC_{scac}, {pallet.pallet_id} created with {len(pallet_packages)} packages at {self.env.now}')\n",
    "                    yield self.queues[staged_queue_name].put(pallet)\n",
    "                    yield self.env.timeout(G.NC_PALLET_STAGING_RATE)\n",
    "                    remaining_packages -= packages_for_this_pallet\n",
    "\n",
    "        yield self.env.process(create_NC_pallets(G.TOTAL_PACKAGES_USPS, USPS_pallets, 'queue_USPS_pallet', 'queue_USPS_staged_pallet','USPS'))\n",
    "\n",
    "\n",
    "    def NC_FDEG_pallet_build(self):\n",
    "        FDEG_pallets = math.ceil(G.TOTAL_PACKAGES_FDEG / G.NC_PALLET_MAX_PACKAGES)\n",
    "        print(f'FDEG: {FDEG_pallets} pallets')\n",
    "        G.FDEG_PALLETS = FDEG_pallets\n",
    "\n",
    "        def create_NC_pallets(NC_packages, NC_pallets, queue_name, staged_queue_name, scac):\n",
    "\n",
    "            with self.current_resource['tm_nonpit_NC'].request(priority=0) as req:\n",
    "                yield req\n",
    "                remaining_packages = NC_packages\n",
    "                for pallet_num in range(NC_pallets):\n",
    "                    pallet_packages = []\n",
    "                    packages_for_this_pallet = min(G.NC_PALLET_MAX_PACKAGES, remaining_packages)\n",
    "                    for _ in range(packages_for_this_pallet):\n",
    "                        pkg = yield self.queues[queue_name].get()\n",
    "                        pallet_packages.append(pkg)\n",
    "                        yield self.env.timeout(0)\n",
    "                    pallet = National_Carrier_Pallet(self.env, f'Pallet_{G.K}', pallet_packages, scac, self.env.now)\n",
    "                    G.K += 1\n",
    "                    print(f'NC_{scac}, {pallet.pallet_id} created with {len(pallet_packages)} packages at {self.env.now}')\n",
    "                    yield self.queues[staged_queue_name].put(pallet)\n",
    "                    yield self.env.timeout(G.NC_PALLET_STAGING_RATE)\n",
    "                    remaining_packages -= packages_for_this_pallet\n",
    "\n",
    "        yield self.env.process(create_NC_pallets(G.TOTAL_PACKAGES_FDEG, FDEG_pallets, 'queue_FDEG_pallet', 'queue_FDEG_staged_pallet','FDEG'))\n",
    "\n",
    "\n",
    "    def NC_FDE_pallet_build(self):\n",
    "        FDE_pallets = math.ceil(G.TOTAL_PACKAGES_FDE / G.NC_PALLET_MAX_PACKAGES)\n",
    "        print(f'FDE: {FDE_pallets} pallets')\n",
    "        G.FDE_PALLETS = FDE_pallets\n",
    "\n",
    "        def create_NC_pallets(NC_packages, NC_pallets, queue_name, staged_queue_name, scac):\n",
    "\n",
    "            with self.current_resource['tm_nonpit_NC'].request(priority=0) as req:\n",
    "                yield req\n",
    "                remaining_packages = NC_packages               \n",
    "                for pallet_num in range(NC_pallets):\n",
    "                    pallet_packages = []\n",
    "                    packages_for_this_pallet = min(G.NC_PALLET_MAX_PACKAGES, remaining_packages)                       \n",
    "                    for _ in range(packages_for_this_pallet):\n",
    "                        pkg = yield self.queues[queue_name].get()\n",
    "                        pallet_packages.append(pkg)\n",
    "                        yield self.env.timeout(0)                        \n",
    "                    pallet = National_Carrier_Pallet(self.env, f'Pallet_{G.K}', pallet_packages, scac, self.env.now)\n",
    "                    G.K += 1\n",
    "                    print(f'NC_{scac}, {pallet.pallet_id} created with {len(pallet_packages)} packages at {self.env.now}')                        \n",
    "                    yield self.queues[staged_queue_name].put(pallet)\n",
    "                    yield self.env.timeout(G.NC_PALLET_STAGING_RATE)                      \n",
    "                    remaining_packages -= packages_for_this_pallet\n",
    "\n",
    "\n",
    "        yield self.env.process(create_NC_pallets(G.TOTAL_PACKAGES_FDE, FDE_pallets, 'queue_FDE_pallet', 'queue_FDE_staged_pallet','FDE'))\n",
    "\n",
    "########################################################\n",
    "##### Begin National Carrier Fluid Load Process#########\n",
    "########################################################\n",
    "\n",
    "    def national_carrier_fluid_split_UPSN(self, package):\n",
    "        with self.self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_UPSN_fluid\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_PICK_RATE)\n",
    "            print(f\"Package {package.tracking_number} sorted to UPSN fluid at {self.env.now}\")\n",
    "            yield self.queues[\"queue_UPSN_truck\"].put(package)\n",
    "            self.env.process(self.national_carrier_fluid_load_UPSN(package))\n",
    "\n",
    "    def national_carrier_fluid_load_UPSN(self, package):\n",
    "        with  self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_UPSN_truck\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_LOAD_RATE)\n",
    "            print(f\"Package {package.tracking_number} fulid loaded to UPSN at {self.env.now}\")\n",
    "            yield self.queues[\"queue_UPSN_Outbound\"].put(package)\n",
    "\n",
    "\n",
    "    def national_carrier_fluid_split_USPS(self, package):\n",
    "        with  self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_USPS_fluid\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_PICK_RATE)\n",
    "            print(f\"Package {package.tracking_number} sorted to USPS fluid at {self.env.now}\")\n",
    "            yield self.queues[\"queue_USPS_truck\"].put(package)\n",
    "            self.env.process(self.national_carrier_fluid_load_USPS(package))\n",
    "\n",
    "    def national_carrier_fluid_load_USPS(self, package):\n",
    "        with  self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_USPS_truck\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_LOAD_RATE)\n",
    "            print(f\"Package {package.tracking_number} fulid loaded to USPS at {self.env.now}\")\n",
    "            yield self.queues[\"queue_USPS_Outbound\"].put(package)\n",
    "\n",
    "\n",
    "\n",
    "    def national_carrier_fluid_split_FDEG(self, package):\n",
    "        with self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_FDEG_fluid\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_PICK_RATE)\n",
    "            print(f\"Package {package.tracking_number} sorted to FDEG fluid at {self.env.now}\")\n",
    "            yield self.queues[\"queue_FDEG_truck\"].put(package)\n",
    "            self.env.process(self.national_carrier_fluid_load_FDEG(package))\n",
    "\n",
    "\n",
    "    def national_carrier_fluid_load_FDEG(self, package):\n",
    "        with self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_FDEG_truck\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_LOAD_RATE)\n",
    "            print(f\"Package {package.tracking_number} fulid loaded to FDEG at {self.env.now}\")\n",
    "            yield self.queues[\"queue_FDEG_Outbound\"].put(package)\n",
    "\n",
    "\n",
    "    def national_carrier_fluid_split_FDE(self, package):\n",
    "        with self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_FDE_fluid\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_PICK_RATE)\n",
    "            print(f\"Package {package.tracking_number} sorted to FDE fluid at {self.env.now}\")\n",
    "            yield self.queues[\"queue_FDE_truck\"].put(package)\n",
    "            self.env.process(self.national_carrier_fluid_load_FDE(package))\n",
    "\n",
    "\n",
    "    def national_carrier_fluid_load_FDE(self, package):\n",
    "      with self.current_resource['tm_nonpit_NC'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues[\"queue_FDE_truck\"].get()\n",
    "            yield self.env.timeout(G.NATIONAL_CARRIER_FLUID_LOAD_RATE)\n",
    "            print(f\"Package {package.tracking_number} fulid loaded to FDE at {self.env.now}\")\n",
    "            yield self.queues[\"queue_FDE_Outbound\"].put(package)\n",
    "\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    ############## Begin TLMD Sort Process #################\n",
    "    ########################################################\n",
    "    \n",
    "    # this will need to be updated to include the logic associated with the different partitions\n",
    "    def tlmd_buffer_sort(self, package):\n",
    "        with self.current_resource['tm_nonpit_buffer'].request(priority=1) as req:\n",
    "            yield req\n",
    "            yield self.queues['queue_tlmd_buffer_sort'].get()\n",
    "            yield self.env.timeout(G.TLMD_BUFFER_SORT_RATE)\n",
    "            print(f'Package {package.tracking_number} sorted to TLMD Buffer at {self.env.now}')\n",
    "            yield self.queues['queue_tlmd_pallet'].put(package)\n",
    "            self.env.process(self.check_all_packages_staged())\n",
    "\n",
    "    \n",
    "    def check_all_packages_staged(self):   \n",
    "        if len(self.queues['queue_tlmd_pallet'].items) == G.TLMD_LINEHAUL_A_PACKAGES + G.TLMD_LINEHAUL_B_PACKAGES + G.TLMD_LINEHAUL_TFC_PACKAGES and not self.TLMD_AB_flag:\n",
    "            self.ab_TLMD_packages_staged_time = self.env.now\n",
    "            G.TLMD_AB_INDUCT_TIME = self.ab_TLMD_packages_staged_time\n",
    "            print(f'All tlmd A&B packages staged at {self.ab_TLMD_packages_staged_time}')\n",
    "            self.TLMD_AB_flag = True\n",
    "            G.TLMD_STAGED_PACKAGES = self.queues['queue_tlmd_pallet'].items\n",
    "            self.env.process(self.TLMD_pallet_build())\n",
    "        elif self.TLMD_AB_flag and len(self.queues['queue_tlmd_pallet'].items) == G.TLMD_LINEHAUL_C_PACKAGES:\n",
    "            self.c_TLDM_packages_staged_time = self.env.now\n",
    "            G.TLMD_C_INDUCT_TIME = self.c_TLDM_packages_staged_time\n",
    "            print(f'All tlmd C packages staged at {self.c_TLDM_packages_staged_time}')\n",
    "            self.env.process(self.TLMD_pallet_build())\n",
    "        else:\n",
    "            #if self.TLMD_AB_flag:\n",
    "                #print('Test of Waiting to palletize')\n",
    "            yield self.env.timeout(1)\n",
    "            self.env.process(self.check_all_packages_staged())\n",
    "\n",
    "\n",
    "    def TLMD_pallet_build(self):\n",
    "    # Calculate the number of packages in each partition\n",
    "        partition_1_packages = round(G.PARTITION_1_RATIO * G.TOTAL_PACKAGES_TLMD)\n",
    "        partition_2_packages = round(G.PARTITION_2_RATIO * G.TOTAL_PACKAGES_TLMD)\n",
    "        partition_3_packages = round(G.PARTITION_3_RATIO * G.TOTAL_PACKAGES_TLMD)\n",
    "\n",
    "        G.TLMD_PARTITION_1_PACKAGES = partition_1_packages\n",
    "        G.TLMD_PARTITION_2_PACKAGES = partition_2_packages\n",
    "        G.TLMD_PARTITION_3_PACKAGES = partition_3_packages\n",
    "\n",
    "        print(f'Partition 1: {partition_1_packages} packages')\n",
    "        print(f'Partition 2: {partition_2_packages} packages')\n",
    "        print(f'Partition 3: {partition_3_packages} packages')\n",
    "        print(f'Total packages: {partition_1_packages + partition_2_packages + partition_3_packages}')\n",
    "\n",
    "        # Handle any rounding discrepancies\n",
    "        if partition_1_packages + partition_2_packages + partition_3_packages != G.TOTAL_PACKAGES_TLMD:\n",
    "            partition_1_packages += G.TOTAL_PACKAGES_TLMD - (partition_1_packages + partition_2_packages + partition_3_packages)\n",
    "            print(f'Adjusted Partition 1: {partition_1_packages} packages')\n",
    "\n",
    "        # Calculate the number of pallets needed for each partition\n",
    "        partition_1_pallets = math.ceil(partition_1_packages / G.TLMD_PARTITION_PALLET_MAX_PACKAGES)\n",
    "        partition_2_pallets = math.ceil(partition_2_packages / G.TLMD_PARTITION_PALLET_MAX_PACKAGES)\n",
    "        partition_3_pallets = math.ceil(partition_3_packages / G.TLMD_PARTITION_PALLET_MAX_PACKAGES)\n",
    "        G.TOTAL_PALLETS_TLMD = partition_1_pallets + partition_2_pallets + partition_3_pallets\n",
    "        print(f'total pallets: {G.TOTAL_PALLETS_TLMD}')\n",
    "        print(f'Partition 1: {partition_1_pallets} pallets')\n",
    "        print(f'Partition 2: {partition_2_pallets} pallets')\n",
    "        \n",
    "\n",
    "        if not self.LHC_flag:\n",
    "            partition_3_packages_actual = len(self.queues['queue_tlmd_pallet'].items) - partition_2_packages - partition_1_packages\n",
    "            partition_3_pallets_actual = math.ceil(partition_3_packages_actual / G.TLMD_PARTITION_PALLET_MAX_PACKAGES)\n",
    "            print(f'Partition 3: {partition_3_pallets_actual} pallets')\n",
    "        elif self.LHC_flag:\n",
    "            partition_3_packages_actual = len(self.queues['queue_tlmd_pallet'].items)\n",
    "            partition_3_pallets_actual = math.ceil(partition_3_packages_actual / G.TLMD_PARTITION_PALLET_MAX_PACKAGES)\n",
    "            print(f'Partition 3 Same Day: {partition_3_pallets} pallets')\n",
    "        # Function to create pallets for a given partition\n",
    "        def create_pallets(partition_packages, partition_pallets, queue_name, staged_queue_name):\n",
    "            while not self.resources_available:\n",
    "                yield self.env.timeout(1)  # Check every 1 time unit\n",
    "\n",
    "            remaining_packages = partition_packages\n",
    "            for pallet_num in range(partition_pallets):\n",
    "                pallet_packages = []\n",
    "                packages_for_this_pallet = min(G.TLMD_PARTITION_PALLET_MAX_PACKAGES, remaining_packages)\n",
    "                for _ in range(packages_for_this_pallet):\n",
    "                    pkg = yield self.queues[queue_name].get()\n",
    "                    pallet_packages.append(pkg)\n",
    "                    yield self.env.timeout(0)\n",
    "                pallet = TLMD_Pallet(self.env, f'Pallet_{G.I}', pallet_packages, self.env.now)\n",
    "                G.I += 1\n",
    "                print(f'TLMD {pallet.pallet_id} created with {len(pallet_packages)} packages at {self.env.now}')\n",
    "                yield self.queues[staged_queue_name].put(pallet)\n",
    "                yield self.env.timeout(0)\n",
    "                self.env.process(self.check_all_pallets_staged())\n",
    "                remaining_packages -= packages_for_this_pallet\n",
    "\n",
    "        # Create pallets for each partition\n",
    "        if not self.LHC_flag:\n",
    "            yield self.env.process(create_pallets(partition_1_packages, partition_1_pallets, 'queue_tlmd_pallet', 'queue_tlmd_1_staged_pallet'))\n",
    "            yield self.env.process(create_pallets(partition_2_packages, partition_2_pallets, 'queue_tlmd_pallet', 'queue_tlmd_2_staged_pallet'))\n",
    "            yield self.env.process(create_pallets(partition_3_packages_actual, partition_3_pallets_actual, 'queue_tlmd_pallet', 'queue_tlmd_3_staged_pallet'))\n",
    "        elif self.LHC_flag:\n",
    "            yield self.env.process(create_pallets(partition_3_packages_actual, partition_3_pallets_actual, 'queue_tlmd_pallet', 'queue_tlmd_3_staged_pallet'))\n",
    "        \n",
    "    def check_all_pallets_staged(self):\n",
    "        while len(self.queues['queue_tlmd_pallet'].items) > 0:\n",
    "            yield self.env.timeout(1)\n",
    "        print(f'All pallets staged at {self.env.now}')\n",
    "        self.env.process(self.feed_TLMD_induct_staging())\n",
    "\n",
    "    def feed_TLMD_induct_staging(self):\n",
    "        while (len(self.queues['queue_tlmd_1_staged_pallet'].items) > 0 or \n",
    "               len(self.queues['queue_tlmd_2_staged_pallet'].items) > 0 or \n",
    "               len(self.queues['queue_tlmd_3_staged_pallet'].items) > 0):\n",
    "\n",
    "            with self.current_resource['tm_TLMD_induct'].request(priority=1) as req:\n",
    "                yield req\n",
    "                if len(self.queues['queue_tlmd_1_staged_pallet'].items) > 0:\n",
    "                    pallet = yield self.queues['queue_tlmd_1_staged_pallet'].get()\n",
    "                    print(f'grabbed pallet {pallet.pallet_id} from queue_tlmd_1_staged_pallet at {self.env.now}')\n",
    "                    print(f'{len(self.queues[\"queue_tlmd_1_staged_pallet\"].items)} pallets left in queue_tlmd_1_staged_pallet')\n",
    "                elif len(self.queues['queue_tlmd_2_staged_pallet'].items) > 0:\n",
    "                    pallet = yield self.queues['queue_tlmd_2_staged_pallet'].get()\n",
    "                    print(f'grabbed pallet {pallet.pallet_id} from queue_tlmd_2_staged_pallet at {self.env.now}')\n",
    "                    print(f'{len(self.queues[\"queue_tlmd_2_staged_pallet\"].items)} pallets left in queue_tlmd_2_staged_pallet')\n",
    "                else:\n",
    "                    pallet = yield self.queues['queue_tlmd_3_staged_pallet'].get()\n",
    "                yield self.env.timeout(G.TLMD_INDUCT_STAGE_RATE)  \n",
    "                pallet.current_queue = 'queue_tlmd_induct_staging_pallets'\n",
    "                yield self.queues['queue_tlmd_induct_staging_pallets'].put(pallet)\n",
    "                print(f'Pallet {pallet.pallet_id} staged for TLMD induction at {self.env.now}')\n",
    "                for package in pallet.packages:\n",
    "                    package.current_queue = 'queue_tlmd_induct_staging_packages'\n",
    "                    yield self.queues['queue_tlmd_induct_staging_packages'].put(package)\n",
    "                    self.env.process(self.tlmd_induct_package(package, pallet))\n",
    "\n",
    "    def tlmd_induct_package(self, package, pallet):\n",
    "\n",
    "        with self.current_resource['tm_TLMD_induct'].request(priority=0) as req:  \n",
    "            yield req\n",
    "            yield self.queues['queue_tlmd_induct_staging_packages'].get()\n",
    "            yield self.env.timeout(G.INDUCTION_RATE)\n",
    "            package.current_queue = 'queue_tlmd_splitter'\n",
    "            print(f'Package {package.tracking_number}, {package.scac} inducted at TLMD at {self.env.now}')\n",
    "            yield self.queues['queue_tlmd_splitter'].put(package)\n",
    "            pallet.current_packages -= 1  \n",
    "            if pallet.current_packages == 0:\n",
    "                # Remove the pallet from queue_induct_staging_pallets\n",
    "                self.tlmd_remove_pallet_from_queue(pallet)\n",
    "            self.env.process(self.tlmd_lane_pickoff(package))\n",
    "\n",
    "    def tlmd_remove_pallet_from_queue(self, pallet):\n",
    "        # Manually search for and remove the pallet from the queue\n",
    "        for i, p in enumerate(self.queues['queue_tlmd_induct_staging_pallets'].items):\n",
    "            if p.pallet_id == pallet.pallet_id:\n",
    "                del self.queues['queue_tlmd_induct_staging_pallets'].items[i]\n",
    "                print(f'Pallet {pallet.pallet_id} removed from queue_tlmd_induct_staging_pallets at {self.env.now}')\n",
    "                break\n",
    "    \n",
    "    def tlmd_lane_pickoff(self, package):\n",
    "\n",
    "        with self.current_resource['tm_TLMD_picker'].request() as req:\n",
    "            yield req\n",
    "            yield self.queues['queue_tlmd_splitter'].get()\n",
    "            yield self.env.timeout(G.SPLITTER_RATE)\n",
    "            package.current_queue = 'queue_tlmd_final_sort'\n",
    "            print(f'Package {package.tracking_number} split to TLMD Final Sort at {self.env.now}')\n",
    "            yield self.queues['queue_tlmd_final_sort'].put(package)\n",
    "            self.env.process(self.tlmd_final_sort(package))\n",
    "    \n",
    "    def tlmd_final_sort(self, package):\n",
    "\n",
    "        with self.current_resource['tm_TLMD_sort'].request() as req:\n",
    "            yield req\n",
    "            yield self.queues['queue_tlmd_final_sort'].get()\n",
    "            yield self.env.timeout(G.TLMD_BUFFER_SORT_RATE)\n",
    "            print(f'Package {package.tracking_number} sorted to TLMD Cart at {self.env.now}')\n",
    "            yield self.queues['queue_tlmd_cart'].put(package)\n",
    "            self.env.process(self.check_all_TLMD_sorted())\n",
    "\n",
    "\n",
    "    def check_all_TLMD_sorted(self):\n",
    "        if (\n",
    "            not self.partition_1_flag\n",
    "            and len(self.queues['queue_tlmd_1_staged_pallet'].items) == 0\n",
    "            and len(self.queues['queue_tlmd_cart'].items) >= G.TLMD_PARTITION_1_PACKAGES\n",
    "        ):\n",
    "                all_packages_staged_time_1 = self.env.now\n",
    "                G.TLMD_PARTITION_1_SORT_TIME = all_packages_staged_time_1\n",
    "                print(f'All partition 1 packages sorted at {all_packages_staged_time_1}')\n",
    "                self.partition_1_flag = True  # Mark this partition as handled\n",
    "\n",
    "        # Check for partition 2 only if partition 1 is done\n",
    "        elif (\n",
    "            not self.partition_2_flag\n",
    "            and self.partition_1_flag  # Ensure partition 1 is done\n",
    "            and len(self.queues['queue_tlmd_2_staged_pallet'].items) == 0\n",
    "            and len(self.queues['queue_tlmd_cart'].items) >= G.TLMD_PARTITION_2_PACKAGES + G.TLMD_PARTITION_1_PACKAGES\n",
    "        ):\n",
    "            all_packages_staged_time_2 = self.env.now\n",
    "            G.TLMD_PARTITION_2_SORT_TIME = all_packages_staged_time_2\n",
    "            print(f'All partition 2 packages sorted at {all_packages_staged_time_2}')\n",
    "            self.partition_2_flag = True  # Mark this partition as handled\n",
    "            \n",
    "\n",
    "        # Check for partition 3 only if partition 2 is done\n",
    "        elif (\n",
    "            not self.partition_3_flag\n",
    "            and self.partition_2_flag  # Ensure partition 2 is done\n",
    "            and len(self.queues['queue_tlmd_cart'].items) >= G.TLMD_PARTITION_3_PACKAGES + G.TLMD_PARTITION_2_PACKAGES + G.TLMD_PARTITION_1_PACKAGES\n",
    "        ):\n",
    "            all_packages_staged_time_3 = self.env.now\n",
    "            G.TLMD_PARTITION_3_SORT_TIME = all_packages_staged_time_3\n",
    "            print(f'All partition 3 packages sorted at {all_packages_staged_time_3}')\n",
    "            self.partition_3_flag = True  # Mark this partition as handled\n",
    "\n",
    "        # Check if all partitions are done\n",
    "        if self.partition_1_flag and self.partition_2_flag and self.partition_3_flag:\n",
    "            G.TLMD_SORTED_PACKAGES = self.queues['queue_tlmd_cart'].items\n",
    "            print(f'All {len(G.TLMD_SORTED_PACKAGES)} TLMD packages sorted at {self.env.now}')\n",
    "            #self.env.process(self.TLMD_cart_build())\n",
    "        \n",
    "        else:\n",
    "            G.PASSED_OVER_PALLETS_1 = self.queues['queue_tlmd_1_staged_pallet'].items\n",
    "            G.PASSED_OVER_PALLETS_2 = self.queues['queue_tlmd_2_staged_pallet'].items\n",
    "            G.PASSED_OVER_PALLETS_3 = self.queues['queue_tlmd_3_staged_pallet'].items\n",
    "\n",
    "        yield self.env.timeout(0)\n",
    "\n",
    "    def TLMD_cart_build(self):\n",
    "        partition_1_packages = G.TLMD_PARTITION_1_PACKAGES\n",
    "        partition_2_packages = G.TLMD_PARTITION_2_PACKAGES\n",
    "        partition_3_packages = G.TLMD_PARTITION_3_PACKAGES\n",
    "    \n",
    "        \n",
    "        print(f'Partition 1: {partition_1_packages} packages')\n",
    "        print(f'Partition 2: {partition_2_packages} packages')\n",
    "        print(f'Partition 3: {partition_3_packages} packages')\n",
    "        print(f'Total packages: {partition_1_packages + partition_2_packages + partition_3_packages}')\n",
    "        \n",
    "        # Calculate the number of pallets needed for each partition\n",
    "        partition_1_carts = math.ceil(partition_1_packages / G.TLMD_CART_MAX_PACKAGES)\n",
    "        partition_2_carts = math.ceil(partition_2_packages / G.TLMD_CART_MAX_PACKAGES)\n",
    "        partition_3_carts = math.ceil(partition_3_packages / G.TLMD_CART_MAX_PACKAGES)\n",
    "\n",
    "        print(f'Partition 1: {partition_1_carts} carts')\n",
    "        print(f'Partition 2: {partition_2_carts} carts')\n",
    "        print(f'Partition 3: {partition_3_carts} carts')\n",
    "        print(F'total carts: {partition_1_carts + partition_2_carts + partition_3_carts}')\n",
    "\n",
    "        G.TOTAL_CARTS_TLMD = partition_1_carts + partition_2_carts + partition_3_carts\n",
    "\n",
    "    def run_simulation(self, until):\n",
    "        return self.env.timeout(until)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2eaa34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_simulation(day_pallets, \n",
    "                    night_tm_pit_unload, \n",
    "                    night_tm_pit_induct, \n",
    "                    night_tm_nonpit_split, \n",
    "                    night_tm_nonpit_NC, \n",
    "                    night_tm_nonpit_buffer,\n",
    "                    night_tm_TLMD_induct,\n",
    "                    night_tm_TLMD_picker,\n",
    "                    night_tm_TLMD_sort,\n",
    "                    night_tm_TLMD_stage,\n",
    "\n",
    "                    day_tm_pit_unload,\n",
    "                    day_tm_pit_induct,\n",
    "                    day_tm_nonpit_split,\n",
    "                    day_tm_nonpit_NC,\n",
    "                    day_tm_nonpit_buffer,\n",
    "                    day_tm_TLMD_induct,\n",
    "                    day_tm_TLMD_picker,\n",
    "                    day_tm_TLMD_sort,\n",
    "                    day_tm_TLMD_stage,\n",
    "                    USPS_Fluid_Status,\n",
    "                    UPSN_Fluid_Status,\n",
    "                    FDEG_Fluid_Status,\n",
    "                    FDE_Fluid_Status,\n",
    "                    unavailable_periods=None,\n",
    "                    night_shift_period=None,\n",
    "                    day_shift_period=None,\n",
    "                    ):\n",
    "        \n",
    "\n",
    "    def sum_packages_by_linehaul(df, linehaul):\n",
    "        filtered_df = df[df['linehaul'] == linehaul]\n",
    "        all_lh_packages = sum([len(row['packages']) for i, row in filtered_df.iterrows()])\n",
    "        return all_lh_packages\n",
    "\n",
    "    total_TMs_night = night_tm_pit_unload + night_tm_pit_induct + night_tm_nonpit_split + night_tm_nonpit_NC + night_tm_nonpit_buffer\n",
    "    total_packages = sum([len(row['packages']) for i, row in day_pallets.iterrows()])\n",
    "    all_packages = [pkg for sublist in day_pallets['packages'] for pkg in sublist]\n",
    "    total_packages_NC = len([pkg for pkg in all_packages if pkg[1] in ['UPSN', 'USPS', 'FDEG', 'FDE']])\n",
    "    total_packages_UPSN = len([pkg for pkg in all_packages if pkg[1] in ['UPSN']])\n",
    "    total_packages_USPS = len([pkg for pkg in all_packages if pkg[1] in ['USPS']])\n",
    "    total_packages_FDEG = len([pkg for pkg in all_packages if pkg[1] in ['FDEG']])\n",
    "    total_packages_FDE = len([pkg for pkg in all_packages if pkg[1] in ['FDE']])\n",
    "    linehaul_A_packages = sum_packages_by_linehaul(day_pallets, 'A')\n",
    "    linehaul_B_packages = sum_packages_by_linehaul(day_pallets, 'B')\n",
    "    linehaul_C_packages = sum_packages_by_linehaul(day_pallets, 'C')\n",
    "    linehaul_TFC_packages = sum_packages_by_linehaul(day_pallets, 'TFC')\n",
    "\n",
    "    def filter_packages_by_linehaul(df, linehaul):\n",
    "        return df[df['linehaul'] == linehaul]\n",
    "\n",
    "    def sum_packages_by_type(filtered_df, package_type):\n",
    "        all_packages = [pkg for sublist in filtered_df['packages'] for pkg in sublist]\n",
    "        target_packages = len([pkg for pkg in all_packages if pkg[1] in [package_type]])\n",
    "        return target_packages\n",
    "\n",
    "\n",
    "    # Filter DataFrames by linehaul\n",
    "    linehaul_A_df = filter_packages_by_linehaul(day_pallets, 'A')\n",
    "    linehaul_B_df = filter_packages_by_linehaul(day_pallets, 'B')\n",
    "    linehaul_C_df = filter_packages_by_linehaul(day_pallets, 'C')\n",
    "    linehaul_TFC_df = filter_packages_by_linehaul(day_pallets, 'TFC')\n",
    "\n",
    "    total_packages_TLMD = total_packages - total_packages_NC\n",
    "\n",
    "    print(f'Total Inbound Packages: {total_packages}')\n",
    "    print(f'Total Inbound TLMD Packages: {total_packages_TLMD}')\n",
    "    print(f'Total Inbound NC Packages: {total_packages_NC}')\n",
    "    print(f'Total Inbound UPSN Packages: {total_packages_UPSN}')\n",
    "    print(f'Total Inbound USPS Packages: {total_packages_USPS}')\n",
    "    print(f'Total Inbound FDEG Packages: {total_packages_FDEG}')\n",
    "    print(f'Total Inbound FDE Packages: {total_packages_FDE}')\n",
    "    print(f'Total Linehaul A Packages: {linehaul_A_packages}')\n",
    "    print(f'Total Linehaul B Packages: {linehaul_B_packages}')\n",
    "    print(f'Total Linehaul C Packages: {linehaul_C_packages}')\n",
    "    print(f'Total Linehaul TFC Packages: {linehaul_TFC_packages}')\n",
    "    \n",
    "    G.LINEHAUL_C_TIME = linehaul_C_df['earliest_arrival'].iloc[0]\n",
    "    G.LINEHAUL_TFC_TIME = linehaul_TFC_df['earliest_arrival'].iloc[0]\n",
    "\n",
    "    G.TOTAL_PACKAGES = total_packages\n",
    "    G.TOTAL_PACKAGES_TLMD = total_packages_TLMD\n",
    "    G.TOTAL_PACKAGES_NC = total_packages_NC \n",
    "    G.TOTAL_PACKAGES_UPSN = total_packages_UPSN\n",
    "    G.TOTAL_PACKAGES_USPS = total_packages_USPS\n",
    "    G.TOTAL_PACKAGES_FDEG = total_packages_FDEG\n",
    "    G.TOTAL_PACKAGES_FDE = total_packages_FDE\n",
    "    G.TOTAL_LINEHAUL_A_PACKAGES = linehaul_A_packages\n",
    "    G.TOTAL_LINEHAUL_B_PACKAGES = linehaul_B_packages\n",
    "    G.TOTAL_LINEHAUL_C_PACKAGES = linehaul_C_packages\n",
    "\n",
    "    G.USPS_LINEHAUL_A_PACKAGES = sum_packages_by_type(linehaul_A_df, 'USPS')\n",
    "    G.UPSN_LINEHAUL_A_PACKAGES = sum_packages_by_type(linehaul_A_df, 'UPSN')\n",
    "    G.FDEG_LINEHAUL_A_PACKAGES = sum_packages_by_type(linehaul_A_df, 'FDEG')\n",
    "    G.FDE_LINEHAUL_A_PACKAGES = sum_packages_by_type(linehaul_A_df, 'FDE')\n",
    "    G.TLMD_LINEHAUL_A_PACKAGES = sum_packages_by_type(linehaul_A_df, 'TLMD')\n",
    "\n",
    "    G.USPS_LINEHAUL_B_PACKAGES = sum_packages_by_type(linehaul_B_df, 'USPS')\n",
    "    G.UPSN_LINEHAUL_B_PACKAGES = sum_packages_by_type(linehaul_B_df, 'UPSN')\n",
    "    G.FDEG_LINEHAUL_B_PACKAGES = sum_packages_by_type(linehaul_B_df, 'FDEG')\n",
    "    G.FDE_LINEHAUL_B_PACKAGES = sum_packages_by_type(linehaul_B_df, 'FDE')\n",
    "    G.TLMD_LINEHAUL_B_PACKAGES = sum_packages_by_type(linehaul_B_df, 'TLMD')\n",
    "\n",
    "    G.USPS_LINEHAUL_C_PACKAGES = sum_packages_by_type(linehaul_C_df, 'USPS')\n",
    "    G.UPSN_LINEHAUL_C_PACKAGES = sum_packages_by_type(linehaul_C_df, 'UPSN')\n",
    "    G.FDEG_LINEHAUL_C_PACKAGES = sum_packages_by_type(linehaul_C_df, 'FDEG')\n",
    "    G.FDE_LINEHAUL_C_PACKAGES = sum_packages_by_type(linehaul_C_df, 'FDE')\n",
    "    G.TLMD_LINEHAUL_C_PACKAGES = sum_packages_by_type(linehaul_C_df, 'TLMD')\n",
    "\n",
    "    G.TLMD_LINEHAUL_TFC_PACKAGES = sum_packages_by_type(linehaul_TFC_df, 'TLMD')\n",
    "    \n",
    "    print(f'Inbound A&B TLMD: {G.TLMD_LINEHAUL_A_PACKAGES+G.TLMD_LINEHAUL_B_PACKAGES}')\n",
    "\n",
    "    env = simpy.Environment()\n",
    "\n",
    "    current_resources = {'tm_pit_unload': None, \n",
    "                        'tm_pit_induct': None, \n",
    "                        'tm_nonpit_split': None, \n",
    "                        'tm_nonpit_NC': None, \n",
    "                        'tm_nonpit_buffer': None,\n",
    "                        'tm_TLMD_induct': None,\n",
    "                        'tm_TLMD_picker': None,\n",
    "                        'tm_TLMD_sort': None,\n",
    "                        'tm_TLMD_stage': None}\n",
    "    \n",
    "    sortation_center = Sortation_Center(\n",
    "        env, \n",
    "        day_pallets, \n",
    "        night_tm_pit_unload, \n",
    "        night_tm_pit_induct, \n",
    "        night_tm_nonpit_split, \n",
    "        night_tm_nonpit_NC, \n",
    "        night_tm_nonpit_buffer,\n",
    "        night_tm_TLMD_induct,\n",
    "        night_tm_TLMD_picker,\n",
    "        night_tm_TLMD_sort,\n",
    "        night_tm_TLMD_stage,\n",
    "        day_tm_pit_unload,\n",
    "        day_tm_pit_induct,\n",
    "        day_tm_nonpit_split,\n",
    "        day_tm_nonpit_NC,\n",
    "        day_tm_nonpit_buffer,\n",
    "        day_tm_TLMD_induct,\n",
    "        day_tm_TLMD_picker,\n",
    "        day_tm_TLMD_sort,\n",
    "        day_tm_TLMD_stage,\n",
    "        USPS_Fluid_Status,\n",
    "        UPSN_Fluid_Status,\n",
    "        FDEG_Fluid_Status,\n",
    "        FDE_Fluid_Status,\n",
    "        current_resources\n",
    "    )\n",
    "\n",
    "    # Start tracking metrics and schedule arrivals\n",
    "    env.process(sortation_center.track_metrics())\n",
    "    sortation_center.schedule_arrivals()\n",
    "\n",
    "    env.process(linehaul_C_arrival(env,sortation_center))\n",
    "\n",
    "    \n",
    "    env.process(manage_resources(env, sortation_center,\n",
    "                                 current_resources,\n",
    "                                 night_tm_pit_unload, \n",
    "                        night_tm_pit_induct, \n",
    "                        night_tm_nonpit_split, \n",
    "                        night_tm_nonpit_NC, \n",
    "                        night_tm_nonpit_buffer,\n",
    "                        night_tm_TLMD_induct,\n",
    "                        night_tm_TLMD_picker,\n",
    "                        night_tm_TLMD_sort,\n",
    "                        night_tm_TLMD_stage,\n",
    "                        day_tm_pit_unload,\n",
    "                        day_tm_pit_induct,\n",
    "                        day_tm_nonpit_split,\n",
    "                        day_tm_nonpit_NC,\n",
    "                        day_tm_nonpit_buffer,\n",
    "                        day_tm_TLMD_induct,\n",
    "                        day_tm_TLMD_picker,\n",
    "                        day_tm_TLMD_sort,\n",
    "                        day_tm_TLMD_stage))\n",
    "\n",
    "   \n",
    "\n",
    "    #night_shift(env, sortation_center, start, end)\n",
    "\n",
    "    return env, sortation_center\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "421ade33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Total Volume: 11783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fenst\\Documents\\Python\\Practice\\demand_generator.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['planned_arrival_datetime'] = pd.to_datetime(filtered_df['planned_arrival_datetime'])\n",
      "c:\\Users\\fenst\\Documents\\Python\\Practice\\demand_generator.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['actual_arrival_datetime'] = pd.to_datetime(filtered_df['actual_arrival_datetime'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Inbound Packages: 11783\n",
      "Total Inbound TLMD Packages: 7110\n",
      "Total Inbound NC Packages: 4673\n",
      "Total Inbound UPSN Packages: 1416\n",
      "Total Inbound USPS Packages: 1782\n",
      "Total Inbound FDEG Packages: 1475\n",
      "Total Inbound FDE Packages: 0\n",
      "Total Linehaul A Packages: 4245\n",
      "Total Linehaul B Packages: 2756\n",
      "Total Linehaul C Packages: 840\n",
      "Total Linehaul TFC Packages: 3942\n",
      "Inbound A&B TLMD: 2813\n",
      "Begin Induct Process\n",
      "Using nightshift resources at time 30\n",
      "Pallet 1 arrived at 70.571282715078\n",
      "Pallet 2 arrived at 70.571282715078\n",
      "Pallet 3 arrived at 70.571282715078\n",
      "Pallet 4 arrived at 70.571282715078\n",
      "Pallet 5 arrived at 70.571282715078\n",
      "Pallet 6 arrived at 70.571282715078\n",
      "Pallet 1 unloaded at 74.571282715078\n",
      "Pallet 2 unloaded at 74.571282715078\n",
      "Pallet 3 unloaded at 74.571282715078\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Put.__init__() got an unexpected keyword argument 'priority'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 164\u001b[0m, in \u001b[0;36mSortation_Center.move_to_induct_staging\u001b[1;34m(self, pallet)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove_to_induct_staging\u001b[39m(\u001b[38;5;28mself\u001b[39m, pallet):\n\u001b[0;32m    159\u001b[0m \n\u001b[0;32m    160\u001b[0m     \n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m#while self.day_shift and not self.partition_2_flag:\u001b[39;00m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;66;03m#yield self.env.timeout(1)\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_resource\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtm_pit_induct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpriority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req: \n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m req\n",
      "\u001b[1;31mTypeError\u001b[0m: Put.__init__() got an unexpected keyword argument 'priority'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 145\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Run inbound induct simulation\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBegin Induct Process\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43muntil\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1140\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd Induct Process\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m#print(len(G.TLMD_STAGED_PACKAGES))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fenst\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\simpy\\core.py:246\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, until)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StopSimulation \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# == until.value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fenst\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\simpy\\core.py:204\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(event\u001b[38;5;241m.\u001b[39m_value)(\u001b[38;5;241m*\u001b[39mevent\u001b[38;5;241m.\u001b[39m_value\u001b[38;5;241m.\u001b[39margs)\n\u001b[0;32m    203\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[1;31mTypeError\u001b[0m: Put.__init__() got an unexpected keyword argument 'priority'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Create a sample dataframe for package arrival data\n",
    "    #csv_path = 'package_arrivals721.csv'\n",
    "    #df = pd.read_csv(csv_path)\n",
    "    \n",
    "    feature_values = {\n",
    "        'yesterday_total_packages': 10152,\n",
    "        'RAFT_known_shipped_pkg_count': 3264,\n",
    "        'RAFT_predicted_carryover_pkg_count': 28,\n",
    "        'RAFT_predicted_total_handoff_pkg_count': 4594,\n",
    "        'Day of Week_Sunday': 0,\n",
    "        'Day of Week_Monday': 1,\n",
    "        'Day of Week_Tuesday': 0,\n",
    "        'Day of Week_Wednesday': 0,\n",
    "        'Day of Week_Thursday': 0,\n",
    "        'Day of Week_Friday': 0,\n",
    "        'Day of Week_Saturday': 0,\n",
    "        'Promotion': 0,\n",
    "        'TMAX': 36.2,\n",
    "        'TMIN': 31.8,\n",
    "        'AWND': 9.87,\n",
    "        'PRCP': 0.912,\n",
    "        'SNOW': 6.14\n",
    "    }\n",
    "\n",
    "    df_pallets = sg.simulation_generator(False, feature_values)\n",
    "\n",
    "    pallet_info = df_pallets.groupby('Pallet').agg(\n",
    "        num_packages=('package_tracking_number', 'count'),\n",
    "        earliest_arrival=('pkg_received_utc_ts', 'min'),\n",
    "        packages=('package_tracking_number', lambda x: list(zip(x, df_pallets.loc[x.index, 'scac']))),\n",
    "        linehaul=('Linehaul', 'first')\n",
    "    ).reset_index()\n",
    "\n",
    "    ### Labor Allocations ###\n",
    "    night_total_tm = 27\n",
    "\n",
    "    night_tm_pit_unload = 3 \n",
    "    night_tm_pit_induct = 5\n",
    "    night_tm_nonpit_split = 1  # must be 1\n",
    "    night_tm_nonpit_NC = 5\n",
    "    night_tm_nonpit_buffer = 13\n",
    "\n",
    "    #NIGHTS TLMD SORT ALLOCATION\n",
    "    night_tm_TLMD_induct = 6\n",
    "    night_tm_TLMD_picker = 4  #Must be 4\n",
    "    night_tm_TLMD_sort = 17\n",
    "\n",
    "    #NIGHTS TLMD STAGE ALLOCATION\n",
    "    night_tm_TLMD_stage = 27\n",
    "    night_tm_TLMD_handoff = 27\n",
    "\n",
    "    day_total_tm = 27\n",
    "\n",
    "    #DAYS INBOUND INDUCT ALLOCATION\n",
    "    day_tm_pit_unload = 3 \n",
    "    day_tm_pit_induct = 5\n",
    "    day_tm_nonpit_split = 1   # must be 1\n",
    "    day_tm_nonpit_NC = 5\n",
    "    day_tm_nonpit_buffer = 13\n",
    "\n",
    "    #NIGHTS TLMD SORT ALLOCATION\n",
    "    day_tm_TLMD_induct = 8\n",
    "    day_tm_TLMD_picker = 4  #Must be 4\n",
    "    day_tm_TLMD_sort = 15\n",
    "    \n",
    "\n",
    "    #NIGHTS TLMD STAGE ALLOCATION\n",
    "    day_tm_TLMD_stage = 27\n",
    "    day_tm_TLMD_handoff = 27\n",
    "\n",
    "    if night_tm_pit_unload + night_tm_pit_induct + night_tm_nonpit_split + night_tm_nonpit_NC + night_tm_nonpit_buffer > night_total_tm:\n",
    "        raise ValueError('Total number of TMs exceeds the limit')   \n",
    "    \n",
    "    if night_tm_TLMD_induct + night_tm_TLMD_picker + night_tm_TLMD_sort  >  night_total_tm:\n",
    "        raise ValueError('Total number of TMs exceeds the limit')\n",
    "\n",
    "    if night_tm_TLMD_stage > night_total_tm or night_tm_TLMD_handoff > night_total_tm:\n",
    "        raise ValueError('Total number of TMs exceeds the limit')\n",
    "    \n",
    "    \n",
    "    if day_tm_pit_unload + day_tm_pit_induct + day_tm_nonpit_split + day_tm_nonpit_NC + day_tm_nonpit_buffer > day_total_tm:\n",
    "        raise ValueError('Total number of TMs exceeds the limit')   \n",
    "    \n",
    "    if day_tm_TLMD_induct + day_tm_TLMD_picker + day_tm_TLMD_sort  >  day_total_tm:\n",
    "        raise ValueError('Total number of TMs exceeds the limit')\n",
    "\n",
    "    if day_tm_TLMD_stage > day_total_tm or day_tm_TLMD_handoff > day_total_tm:\n",
    "        raise ValueError('Total number of TMs exceeds the limit')\n",
    "    \n",
    "    USPS_Fluid_Status = False\n",
    "    UPSN_Fluid_Status = False\n",
    "    FDEG_Fluid_Status = False\n",
    "    FDE_Fluid_Status = False\n",
    "    \n",
    "    unavailable_periods = [\n",
    "        # (180, 210),  # Night shift bk1\n",
    "        # (420, 435),  # Night shift bk2\n",
    "        # (800, 810),  # Night shift shift gap\n",
    "        # (990, 1020),  # Day shift break 1\n",
    "        # (1230, 1245),  # Day shift break 2\n",
    "        # (1410, 1440)  # Day shift shift gap\n",
    "    ]\n",
    "\n",
    "    night_shift_period = [\n",
    "        (30, 600)\n",
    "    ]\n",
    "\n",
    "    day_shift_period = [\n",
    "        (601, 1140)\n",
    "    ]\n",
    "\n",
    "    # Setup inbound induct simulation\n",
    "    env, sortation_center = setup_simulation(pallet_info, \n",
    "                                             night_tm_pit_unload, \n",
    "                                             night_tm_pit_induct, \n",
    "                                             night_tm_nonpit_split, \n",
    "                                             night_tm_nonpit_NC, \n",
    "                                             night_tm_nonpit_buffer,\n",
    "                                             night_tm_TLMD_induct,\n",
    "                                             night_tm_TLMD_picker,\n",
    "                                             night_tm_TLMD_sort, \n",
    "                                             night_tm_TLMD_stage,\n",
    "                                             day_tm_pit_unload,\n",
    "                                             day_tm_pit_induct,\n",
    "                                             day_tm_nonpit_split,\n",
    "                                             day_tm_nonpit_NC,\n",
    "                                             day_tm_nonpit_buffer,\n",
    "                                             day_tm_TLMD_induct,\n",
    "                                             day_tm_TLMD_picker,\n",
    "                                             day_tm_TLMD_sort,\n",
    "                                             day_tm_TLMD_stage,\n",
    "                                             USPS_Fluid_Status,\n",
    "                                             UPSN_Fluid_Status,\n",
    "                                             FDEG_Fluid_Status,\n",
    "                                             FDE_Fluid_Status,\n",
    "                                             unavailable_periods,\n",
    "                                             night_shift_period,\n",
    "                                             day_shift_period\n",
    "                                             )   \n",
    "\n",
    "\n",
    "    # Run inbound induct simulation\n",
    "    print(\"Begin Induct Process\")\n",
    "    env.run(until=1140)\n",
    "    print(\"End Induct Process\")\n",
    "    #print(len(G.TLMD_STAGED_PACKAGES))\n",
    "    plot_metrics(sortation_center.metrics)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d69b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Induct Line Run as Batch Process:')\n",
    "print(\"...................................\")\n",
    "print(f'Primary Induct process completed at {G.TLMD_AB_INDUCT_TIME}')\n",
    "print(f'UPSN Packages staged for handoff at {G.UPSN_SORT_TIME}')\n",
    "print(f'USPS Packages staged for handoff at {G.USPS_SORT_TIME}')\n",
    "print(f'FDEG Packages staged for handoff at {G.FDEG_SORT_TIME}')\n",
    "print(f'FDE Packages staged for handoff at {G.FDE_SORT_TIME}')\n",
    "\n",
    "print(\"...................................\")\n",
    "print(f'Begin TLMD Sort Process:')\n",
    "print(\"...................................\")\n",
    "print(f'Partition 1 sort process completed at {G.TLMD_PARTITION_1_SORT_TIME}')\n",
    "print(f'Partition 2 sort process completed at {G.TLMD_PARTITION_2_SORT_TIME}')\n",
    "print(f'Partition 3 sort process completed at {G.TLMD_PARTITION_3_SORT_TIME}')\n",
    "#print(f'Partition 1 cart staging completed at {G.TLMD_PARTITION_1_CART_STAGE_TIME}')\n",
    "#print(f'Partition 2 cart staging completed at {G.TLMD_PARTITION_2_CART_STAGE_TIME}')\n",
    "#print(f'Partition 3 cart staging completed at {G.TLMD_PARTITION_3_CART_STAGE_TIME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490b61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.TLMD_LINEHAUL_A_PACKAGES +G.TLMD_LINEHAUL_B_PACKAGES+G.TLMD_LINEHAUL_C_PACKAGES)\n",
    "print(G.TLMD_LINEHAUL_A_PACKAGES +G.TLMD_LINEHAUL_B_PACKAGES+G.TLMD_LINEHAUL_TFC_PACKAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae0940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Given values\n",
    "TOTAL_PACKAGES = G.TOTAL_PACKAGES  # Example value, replace with actual value\n",
    "TLMD_INDUCT_TIME = G.TLMD_AB_INDUCT_TIME  # Example value, replace with actual value\n",
    "\n",
    "induct_rate = G.TOTAL_PACKAGES  / G.TLMD_AB_INDUCT_TIME\n",
    "full_induct_time = G.TLMD_AB_INDUCT_TIME + 45\n",
    "\n",
    "break_1 = (180, 210)\n",
    "break_2 = (420, 435)\n",
    "\n",
    "# Generate time points\n",
    "time_points = np.arange(0, full_induct_time + 1)\n",
    "\n",
    "# Generate cumulative packages inducted with breaks\n",
    "cumulative_packages = []\n",
    "cumulative_sum = 0\n",
    "for t in time_points:\n",
    "    if break_1[0] <= t <= break_1[1] or break_2[0] <= t <= break_2[1]:\n",
    "        cumulative_packages.append(cumulative_sum)\n",
    "    else:\n",
    "        cumulative_sum += induct_rate\n",
    "        cumulative_packages.append(cumulative_sum)\n",
    "\n",
    "# Plot the graph\n",
    "plt.plot(time_points, cumulative_packages, label='Cumulative Packages Inducted')\n",
    "plt.xlabel('Time (minutes)')\n",
    "plt.ylabel('Cumulative Packages Inducted')\n",
    "plt.title('Cumulative Packages Inducted Over Time with Breaks')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9738fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from chat gpt, need to revise to use for my simulatin\n",
    "\n",
    "# Define the process that uses the resource\n",
    "def process(env, name, resource):\n",
    "    with resource.request() as req:\n",
    "        yield req\n",
    "        print(f'{name} starting at {env.now}')\n",
    "        # Simulate some work done\n",
    "        yield env.timeout(5)\n",
    "        print(f'{name} finished at {env.now}')\n",
    "\n",
    "# Change resources based on time\n",
    "def manage_resources(env, day_shift_1, day_shift_5):\n",
    "    # First 10 minutes with 1 resource\n",
    "    current_resource = day_shift_1\n",
    "    print(f\"Using day shift 1 resource at time {env.now}\")\n",
    "    \n",
    "    # Simulate 10 minutes with 1 resource\n",
    "    yield env.timeout(10)\n",
    "    \n",
    "    # After 10 minutes, switch to 5 resources\n",
    "    current_resource = day_shift_5\n",
    "    print(f\"Switching to day shift 5 resources at time {env.now}\")\n",
    "    \n",
    "    # Run with 5 resources for 30 more minutes\n",
    "    yield env.timeout(30)\n",
    "    \n",
    "# Initialize the environment\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Create resources\n",
    "day_shift_1 = simpy.Resource(env, capacity=1)\n",
    "day_shift_5 = simpy.Resource(env, capacity=5)\n",
    "\n",
    "# Start the resource manager\n",
    "env.process(manage_resources(env, day_shift_1, day_shift_5))\n",
    "\n",
    "# Start processes that will request resources\n",
    "for i in range(10):\n",
    "    env.process(process(env, f'Process {i}', day_shift_1))\n",
    "\n",
    "# Run the simulation for 40 minutes\n",
    "env.run(until=40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
