{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________Performing Training for 20 Hidden Dimension_______\n",
      "Mean Train MSE at step 0: 8.383168441613515\n",
      "Mean Train MSE at step 10: 0.3521849141319593\n",
      "Mean Train MSE at step 20: 0.3442471093734105\n",
      "Mean Train MSE at step 30: 0.3346062982479731\n",
      "Mean Train MSE at step 40: 0.32257778390248615\n",
      "Train MSE for feature method genre_info, k=20 is: 0.3080405592918396\n",
      "Validation MSE for feature method genre_info, k=20 is: 0.8310539126396179\n",
      "_________Performing Training for 60 Hidden Dimension_______\n",
      "Mean Train MSE at step 0: 6.3668738938172655\n",
      "Mean Train MSE at step 10: 0.3528557370503744\n",
      "Mean Train MSE at step 20: 0.34467610289653144\n",
      "Mean Train MSE at step 30: 0.3342654260396957\n",
      "Mean Train MSE at step 40: 0.32089368091026943\n",
      "Train MSE for feature method genre_info, k=60 is: 0.3043701946735382\n",
      "Validation MSE for feature method genre_info, k=60 is: 0.8280117511749268\n",
      "_________Performing Training for 100 Hidden Dimension_______\n",
      "Mean Train MSE at step 0: 6.254701234141986\n",
      "Mean Train MSE at step 10: 0.34464760186274845\n",
      "Mean Train MSE at step 20: 0.3301549097100894\n",
      "Mean Train MSE at step 30: 0.3137901267806689\n",
      "Mean Train MSE at step 40: 0.29454691686232887\n",
      "Train MSE for feature method genre_info, k=100 is: 0.27152734994888306\n",
      "Validation MSE for feature method genre_info, k=100 is: 0.7986071109771729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch  # download & install PyTorch here:  https://pytorch.org/get-started/locally/\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# You also need to install the libraries listed above\n",
    "# This can be done with: pip install pandas numpy\n",
    "\n",
    "\n",
    "##########################################\n",
    "##  Helper Functions (Provided for you) ##\n",
    "##########################################\n",
    "\n",
    "def train_model(X_train, y_train, k, max_iter=50, batch_size=32, print_n=10, verbose=True):\n",
    "    '''\n",
    "    Trains neural network model on X_train, y_train data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        matrix of training data features\n",
    "    y_train: np.array\n",
    "        vector of training data labels\n",
    "    k: int\n",
    "        size of hidden layer to use in neural network\n",
    "    max_iter: int\n",
    "        maximum number of iterations to train for\n",
    "    batch_size: int\n",
    "        batch size to use when training w/ SGD\n",
    "    print_n: int\n",
    "        print training progress every print_n steps\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    '''\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "    # intialize neural network\n",
    "    n_samples, n_features = X_train_tensor.shape\n",
    "    nn_model = NN(n_features, k)\n",
    "    nn_model.train()  # put model in train mode\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # train with (mini-batch) SGD; initialize optimizer\n",
    "    opt = torch.optim.SGD(nn_model.parameters(), lr=0.001)\n",
    "    for it in range(max_iter):\n",
    "        # save losses across all batches\n",
    "        losses = []\n",
    "        # loop through data in batches\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            # reset gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # form batch\n",
    "            X_batch = X_train_tensor[batch_start:batch_start+batch_size]\n",
    "            y_batch = y_train_tensor[batch_start:batch_start+batch_size]\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            # compute MSE loss\n",
    "            loss = mse_loss(y_pred, y_batch[:, None].float())\n",
    "            # back-propagate loss\n",
    "            loss.backward()\n",
    "            # update model parameters based on backpropogated gradients\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "        if verbose and it % print_n == 0:\n",
    "            print(f\"Mean Train MSE at step {it}: {np.mean(losses)}\")\n",
    "    return nn_model\n",
    "\n",
    "\n",
    "def evaluate_model(nn_model, X_eval, y_eval, batch_size=32):\n",
    "    '''\n",
    "    Evaluates trained neural network model on X_eval, y_eval data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    X_eval: np.array\n",
    "        matrix of training data features\n",
    "    y_eval: np.array\n",
    "        vector of training data labels\n",
    "    batch_size: int\n",
    "        batch size to looping over dataset to generate predictions\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse: float\n",
    "        MSE of trained model on X_eval, y_eval data\n",
    "    '''\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_eval_tensor = torch.tensor(X_eval)\n",
    "    y_eval_tensor = torch.tensor(y_eval)\n",
    "    n_samples = X_eval_tensor.shape[0]\n",
    "    nn_model.eval() # put in eval mode\n",
    "    # loop over data and generate predictions\n",
    "    preds = []\n",
    "    for batch_start in range(0, n_samples, batch_size):\n",
    "        # form batch\n",
    "        X_batch = X_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        y_batch = y_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        with torch.no_grad():  # no need to compute gradients during evaluation\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            preds.append(y_pred)\n",
    "    # compute MSE across all samples\n",
    "    all_preds = torch.cat(preds)\n",
    "    loss = mse_loss(all_preds, y_eval_tensor[:, None].float()).item()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def read_data(ratings_fp):\n",
    "    '''\n",
    "    Reads book ratings from book_ratings.csv file, splits into train, validation, and test groups,\n",
    "    and produces a Pandas dataframe with the ratings for each. Each dataframe contains the\n",
    "    columns: UserID, bookID, rating. There is a row for each rating in the dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings_fp: str\n",
    "        Path to book_ratings.csv file\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    train_df: pd.DataFrame\n",
    "        DataFrame for each book rating in the train dataset\n",
    "    val_df: pd.DataFrame\n",
    "        DataFrame for each book rating in the train dataset\n",
    "    test_df: pd.DataFrame\n",
    "        DataFrame for each book rating in the train dataset\n",
    "    n_users: int\n",
    "        total number of users in dataset\n",
    "    n_books: int\n",
    "        total number of books in dataset\n",
    "    '''\n",
    "    # read data\n",
    "    ratings_df = pd.read_csv(ratings_fp)\n",
    "    n_users = len(ratings_df['userId'].unique())\n",
    "    n_books = len(ratings_df['bookId'].unique())\n",
    "    # split into train, val, test\n",
    "    train_df = ratings_df[ratings_df[\"split\"] == \"train\"]\n",
    "    val_df = ratings_df[ratings_df[\"split\"] == \"val\"]\n",
    "    test_df = ratings_df[ratings_df[\"split\"] == \"test\"]\n",
    "    # reset their indices\n",
    "    train_df = train_df.reset_index()\n",
    "    val_df = val_df.reset_index()\n",
    "    test_df = test_df.reset_index()\n",
    "    return train_df, val_df, test_df, n_users, n_books\n",
    "\n",
    "\n",
    "def get_genre_id(genre_str):\n",
    "    '''\n",
    "    Returns unique integer ID (single digit in range 0-19) associated with the given genre.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    genre_str: string specifying a single genre name: e.g., \"Fantasy\"\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    genre_id: int\n",
    "        ID in range [0, 19]\n",
    "    '''\n",
    "    \n",
    "    GENRE_ID_DICT = {'Fantasy': 0,\n",
    "                     'Science Fiction': 1,\n",
    "                     'Mystery': 2,\n",
    "                     'Romance': 3,\n",
    "                     'Thriller': 4,\n",
    "                     'Horror': 5,\n",
    "                     'Non-fiction': 6,\n",
    "                     'Historical Fiction': 7,\n",
    "                     'Biography': 8,\n",
    "                     'Self-help': 9,\n",
    "                     'Young Adult': 10,\n",
    "                     'Poetry': 11,\n",
    "                     'Humor': 12,\n",
    "                     'Cooking': 13,\n",
    "                     'Travel': 14,\n",
    "                     'Art': 15,\n",
    "                     'Business': 16,\n",
    "                     'Science': 17,\n",
    "                     'Health': 18,\n",
    "                     'Fitness': 19\n",
    "                     }\n",
    "    return GENRE_ID_DICT[genre_str]\n",
    "\n",
    "\n",
    "#####################################\n",
    "##  Neural Network Implementation  ##\n",
    "#####################################\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#######################\n",
    "##  Data Processing  ##\n",
    "#######################\n",
    "\n",
    "\n",
    "def process_data_one_hot(ratings_df, N, M):\n",
    "    '''\n",
    "    Creates dataset of book ratings to use for neural network model training or validation.\n",
    "    For each rating (i.e., datapoint) in ratings_df, create the following (x, y) pair:\n",
    "    - x consists of two concatenated one-hot vectors: one for the user n, and one for the book m\n",
    "    - y is the rating that user n gave book m\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings_df: pd.DataFrame\n",
    "        Contains a row for each rating (i.e., datapoint) in the dataset. For each row, contains the following information:\n",
    "        -- userId: unique ID identifying user\n",
    "        -- bookId: unqiue ID identifying book\n",
    "        -- rating: rating given to book of bookID by user of userID\n",
    "        -- genres: string listing genres of book, with multiple books separated by a single \"|\" character\n",
    "            e.g., Adventure|Animation|Children|Comedy|Fantasy\n",
    "    N: int\n",
    "        total number of users\n",
    "    M: int\n",
    "        total number of books\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    X: np.array \n",
    "        matrix of size R x (N + M), where R is the number of ratings in ratings_df, \n",
    "        N is the total number of users, and M is the total number of books.\n",
    "    y: np.array \n",
    "        vector of size R of book ratings\n",
    "    '''\n",
    "    X = np.zeros((len(ratings_df), N + M))\n",
    "    y = np.zeros(len(ratings_df))\n",
    "\n",
    "    for i, row in ratings_df.iterrows():\n",
    "\n",
    "        user_id = row['userId']\n",
    "        book_id = row['bookId']\n",
    "        rating = row['rating']\n",
    "\n",
    "        user_vector = np.zeros(N)\n",
    "        user_vector[user_id] = 1\n",
    "        book_vector = np.zeros(M)\n",
    "        book_vector[book_id] = 1\n",
    "\n",
    "        concatenated_vector = np.concatenate([user_vector, book_vector])\n",
    "\n",
    "        X[i] = concatenated_vector\n",
    "        y[i] = rating\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def process_data_with_genres(ratings_df, N, M):\n",
    "    '''\n",
    "    Creates dataset of book ratings to use for neural network model training or validation.\n",
    "    For each rating (i.e., datapoint) in ratings_df, create the following (x, y) pair:\n",
    "    - x consists of features that describe a user u and a book m\n",
    "        -- Hint: since for users you don't have additional info, a one-hot encoding is still best, but \n",
    "            for books you can decide how to incorporate the genre information\n",
    "    - y is the rating that user n gave book m\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings_df: pd.DataFrame\n",
    "        Contains a row for each rating (i.e., datapoint) in the dataset. For each row, contains the following information:\n",
    "        -- userID: unique ID identifying user\n",
    "        -- bookID: unqiue ID identifying book\n",
    "        -- rating: rating given to book of bookID by user of userID\n",
    "        -- genres: string listing genres of book, with multiple books separated by a single \"|\" character\n",
    "            e.g., Adventure|Animation|Children|Comedy|Fantasy\n",
    "    N: int\n",
    "        total number of users\n",
    "    M: int\n",
    "        total number of books\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    X: np.array \n",
    "        matrix of size R x F, where R is the number of ratings in ratings_df, \n",
    "        and F is the number of features used to describe a (user, book) pair\n",
    "    y: np.array \n",
    "        vector of size R of book ratings\n",
    "    '''\n",
    "    N_GENRES = 20  # total number of possible genres\n",
    "    X = np.zeros((len(ratings_df), N + M + N_GENRES))\n",
    "    y = np.zeros(len(ratings_df))\n",
    "    \n",
    "    for i, row in ratings_df.iterrows():\n",
    "        user_id = row['userId']\n",
    "        book_id = row['bookId']\n",
    "        rating = row['rating']\n",
    "        genres = row['genres']\n",
    "\n",
    "        genres_list = genres.split(\"|\")\n",
    "        genres_num=[]\n",
    "\n",
    "        for genre in genres_list:\n",
    "            genres_num.append(get_genre_id(genre))\n",
    "            \n",
    "        #normalize the genre_num\n",
    "        genres_num = np.array(genres_num)\n",
    "        genre_vector = np.zeros(N_GENRES)\n",
    "        for genre in genres_num:\n",
    "            genre_vector[genre] = 1\n",
    "\n",
    "\n",
    "        genre_vector_norm = genre_vector/np.sum(genre_vector)\n",
    "\n",
    "        book_vector = np.zeros(M)\n",
    "        book_vector[book_id] = 1\n",
    "\n",
    "        user_vector = np.zeros(N)\n",
    "        user_vector[user_id] = 1\n",
    "\n",
    "\n",
    "        concatenated_vector = np.concatenate([user_vector, book_vector, genre_vector_norm])\n",
    "\n",
    "        X[i] = concatenated_vector\n",
    "        y[i] = rating  \n",
    "\n",
    "    # TODO: fill the feature and label vectors\n",
    "    # hint #1: you can loop through each row in the DataFrame using ratings_df.iterrows()\n",
    "    # hint #2: you can access the value of an attribute at a row via row[\"<column_name>\"]\n",
    "    # hint #3: you may find the get_genre_id helper function above useful!\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "#########################################\n",
    "##  Code to Run Training & Evaluation  ##\n",
    "#########################################\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load data used for training and evaluation\n",
    "    path_to_ratings_file = \"book_ratings.csv\"\n",
    "    train_df, val_df, test_df, n_users, n_books = read_data(path_to_ratings_file)\n",
    "\n",
    "    METHOD = \"genre_info\"  # change this to \"genre_info\" to test the other approach!\n",
    "\n",
    "    # get feature label pairs (x, y) from ratings dataframes\n",
    "    if METHOD == \"one_hot\":\n",
    "        X_train, y_train = process_data_one_hot(train_df, n_users, n_books)\n",
    "        X_val, y_val = process_data_one_hot(val_df, n_users, n_books)\n",
    "    else: # method is \"genre_info\"\n",
    "        X_train, y_train = process_data_with_genres(train_df, n_users, n_books)\n",
    "        X_val, y_val = process_data_with_genres(val_df, n_users, n_books)\n",
    "\n",
    "    # train NN model to predict rating from user + book features using train data\n",
    "    for k in [20, 60, 100]:\n",
    "        print('_________Performing Training for %d Hidden Dimension_______'%k)\n",
    "        nn_model = train_model(X_train, y_train, k)\n",
    "        # evaluate performance of final model on train data\n",
    "        train_mse = evaluate_model(nn_model, X_train, y_train)\n",
    "        print(f\"Train MSE for feature method {METHOD}, k={k} is: {train_mse}\")\n",
    "        # evaluate performance of model on validation data\n",
    "        val_mse = evaluate_model(nn_model, X_val, y_val)\n",
    "        print(f\"Validation MSE for feature method {METHOD}, k={k} is: {val_mse}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 Question 3<br>\n",
    "\n",
    "|K|20|60|100|\n",
    "|-|-|-|-|\n",
    "|Train|0.3224|0.3204|0.3170|\n",
    "|Val|0.8550|0.8353|0.8525|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 Question 4<br>\n",
    "|K|20|60|100|\n",
    "|-|-|-|-|\n",
    "|Train|0.3080|0.3044|0.2715|\n",
    "|Val|0.8311|0.8280|0.7986|\n",
    "\n",
    "The incorporation of the genre feature has improved both the training and the validation MSE in all 3 cases of hidden layer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
